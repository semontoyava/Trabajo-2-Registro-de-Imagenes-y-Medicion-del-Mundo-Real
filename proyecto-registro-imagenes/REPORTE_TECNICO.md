# ğŸ“¸ Registro de ImÃ¡genes y MediciÃ³n del Mundo Real: De MÃºltiples Vistas a un Panorama Calibrado

**Universidad Nacional de Colombia - Facultad de Minas**  
**VisiÃ³n por Computador - 3009228**  
**Semestre 2025-02**  
**Autores:** David LondoÃ±o, AndrÃ©s Churio, SebastiÃ¡n Montoya Vargas
**Fecha:** Octubre 27, 2025

---

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Marco TeÃ³rico](#marco-teÃ³rico)
3. [MetodologÃ­a](#metodologÃ­a)
4. [Experimentos y Resultados](#experimentos-y-resultados)
5. [AnÃ¡lisis y DiscusiÃ³n](#anÃ¡lisis-y-discusiÃ³n)
6. [Conclusiones](#conclusiones)
7. [Referencias](#referencias)
8. [AnÃ¡lisis de ContribuciÃ³n Individual](#anÃ¡lisis-de-contribuciÃ³n-individual)

---

## 1. IntroducciÃ³n

### 1.1 Contexto del Problema

El **registro de imÃ¡genes** (image registration) es uno de los problemas fundamentales en visiÃ³n por computador. Consiste en alinear geomÃ©tricamente dos o mÃ¡s imÃ¡genes de la misma escena tomadas desde diferentes puntos de vista, en diferentes momentos, o con diferentes sensores [1]. Esta tÃ©cnica tiene aplicaciones crÃ­ticas en:

- ğŸ“¸ **CreaciÃ³n de panoramas** (fotografÃ­a computacional)
- ğŸ¥ **Imagen mÃ©dica** (fusiÃ³n de CT, MRI, PET)
- ğŸ›°ï¸ **TeledetecciÃ³n** (anÃ¡lisis multitemporal de satÃ©lites)
- ğŸ¤– **RobÃ³tica mÃ³vil** (navegaciÃ³n y SLAM)
- ğŸ¬ **Realidad aumentada** (alineaciÃ³n de contenido virtual)

### 1.2 MotivaciÃ³n

Este trabajo aborda un problema prÃ¡ctico: dado un conjunto de 3 fotografÃ­as de un comedor tomadas desde diferentes posiciones, Â¿cÃ³mo podemos:

1. **Fusionarlas** en una vista coherente y continua?
2. **Calibrar** el sistema usando objetos de referencia conocidos?
3. **Medir** dimensiones de objetos en el mundo real?

El desafÃ­o tÃ©cnico radica en que las imÃ¡genes tienen:
- âœ… **Solapamiento parcial** (no total)
- âœ… **Diferentes perspectivas** (cambios de punto de vista)
- âœ… **Diferentes escalas** (una imagen tiene resoluciÃ³n distinta)
- âœ… **Variaciones de iluminaciÃ³n** (condiciones de captura diferentes)

### 1.3 Objetivos

**Objetivo General:**  
Implementar un pipeline completo de registro de imÃ¡genes que permita fusionar mÃºltiples vistas y realizar mediciones calibradas del mundo real.

**Objetivos EspecÃ­ficos:**
1. Validar algoritmos de registro usando el dataset Graf (imÃ¡genes sintÃ©ticas con ground truth)
2. Detectar y emparejar caracterÃ­sticas robustas entre imÃ¡genes con SIFT y ORB
3. Estimar transformaciones geomÃ©tricas usando RANSAC
4. Fusionar imÃ¡genes en panoramas coherentes
5. Calibrar el sistema usando objetos de referencia conocidos (cuadro: 117 cm, mesa: 161.1 cm)
6. Desarrollar herramienta interactiva de mediciÃ³n con anÃ¡lisis de incertidumbre

---

## 2. Marco TeÃ³rico

### 2.1 DetecciÃ³n de CaracterÃ­sticas

#### 2.1.1 SIFT (Scale-Invariant Feature Transform)

SIFT, propuesto por David Lowe en 2004 [1], es uno de los detectores de caracterÃ­sticas mÃ¡s robustos. Su pipeline consta de 4 etapas:

**1. DetecciÃ³n de Extremos en el Espacio-Escala:**
```
L(x, y, Ïƒ) = G(x, y, Ïƒ) * I(x, y)
```
Donde `G(x, y, Ïƒ)` es un filtro Gaussiano con desviaciÃ³n estÃ¡ndar `Ïƒ` e `I(x, y)` es la imagen.

Se detectan extremos en la funciÃ³n Difference-of-Gaussian (DoG):
```
D(x, y, Ïƒ) = L(x, y, kÏƒ) - L(x, y, Ïƒ)
```

**2. LocalizaciÃ³n Precisa de Keypoints:**
- Refinamiento sub-pÃ­xel usando interpolaciÃ³n cuadrÃ¡tica
- EliminaciÃ³n de puntos de baja contraste
- EliminaciÃ³n de respuestas en bordes (usando matriz Hessiana)

**3. AsignaciÃ³n de OrientaciÃ³n:**
- Histograma de gradientes en vecindario del keypoint
- OrientaciÃ³n dominante garantiza invarianza a rotaciÃ³n

**4. Descriptor Local:**
- Histogramas de gradientes 4x4 en regiÃ³n 16x16
- Vector de 128 dimensiones normalizado

**Ventajas de SIFT:**
- âœ… Invariante a escala, rotaciÃ³n e iluminaciÃ³n
- âœ… Alta repetibilidad (>80% en cambios severos)
- âœ… Descriptores altamente distintivos

**Desventajas:**
- âŒ Computacionalmente costoso (~500ms/imagen)
- âŒ Patentado (aunque libre para uso acadÃ©mico)

#### 2.1.2 ORB (Oriented FAST and Rotated BRIEF)

ORB, propuesto por Rublee et al. en 2011 [2], es una alternativa eficiente y de cÃ³digo abierto:

**1. DetecciÃ³n con oFAST (oriented FAST):**
- FAST: Compara intensidad del pÃ­xel con vecinos en cÃ­rculo
- OrientaciÃ³n: Calculada usando momentos de la imagen

**2. Descriptor rBRIEF (rotated BRIEF):**
- BRIEF: Comparaciones binarias de pares de pÃ­xeles
- RotaciÃ³n: OrientaciÃ³n de oFAST aplicada al patrÃ³n BRIEF

**Ventajas de ORB:**
- âœ… Muy rÃ¡pido (~50ms/imagen)
- âœ… CÃ³digo abierto (sin patentes)
- âœ… Descriptores binarios (emparejamiento rÃ¡pido)

**Desventajas:**
- âŒ Menos robusto a cambios de escala
- âŒ Menor repetibilidad que SIFT

### 2.2 Emparejamiento de CaracterÃ­sticas

#### 2.2.1 FLANN (Fast Library for Approximate Nearest Neighbors)

FLANN [3] usa estructuras de datos jerÃ¡rquicas (Ã¡rboles KD, Ã¡rboles k-means) para bÃºsqueda eficiente en espacios de alta dimensiÃ³n.

**Algoritmo de emparejamiento:**
```python
for cada descriptor d1 en imagen1:
    encontrar 2 vecinos mÃ¡s cercanos en imagen2: (d2a, d2b)
    ratio = distancia(d1, d2a) / distancia(d1, d2b)
    if ratio < threshold (tÃ­picamente 0.75):
        aceptar match (d1, d2a)
```

Este **ratio test**, propuesto por Lowe [1], filtra matches ambiguos.

#### 2.2.2 BruteForce con Hamming

Para descriptores binarios (ORB), se usa distancia Hamming:
```
distancia_hamming(a, b) = nÃºmero de bits diferentes
```

### 2.3 EstimaciÃ³n de HomografÃ­a con RANSAC

#### 2.3.1 Modelo de HomografÃ­a

Una homografÃ­a es una transformaciÃ³n proyectiva que relaciona puntos entre dos planos:

```
[x']     [h11  h12  h13]   [x]
[y']  ~  [h21  h22  h23] * [y]
[1 ]     [h31  h32  h33]   [1]
```

En forma no homogÃ©nea:
```
x' = (h11*x + h12*y + h13) / (h31*x + h32*y + h33)
y' = (h21*x + h22*y + h23) / (h31*x + h32*y + h33)
```

**Propiedades:**
- 8 grados de libertad (matriz 3x3 normalizada)
- Preserva lÃ­neas rectas
- No preserva Ã¡ngulos ni distancias (excepto casos especiales)

#### 2.3.2 RANSAC (Random Sample Consensus)

RANSAC [4] es un mÃ©todo robusto para estimar modelos en presencia de outliers.

**Algoritmo:**
```
repetir N veces:
    1. Seleccionar muestra aleatoria mÃ­nima (4 puntos para homografÃ­a)
    2. Ajustar modelo a la muestra
    3. Contar inliers (puntos con error < threshold)
    4. Si #inliers > mejor_hasta_ahora:
        guardar modelo y conjunto de inliers

re-estimar modelo usando todos los inliers del mejor conjunto
```

**NÃºmero de iteraciones:**
```
N = log(1 - p) / log(1 - w^s)
```
Donde:
- `p` = probabilidad deseada de Ã©xito (tÃ­picamente 0.99)
- `w` = fracciÃ³n esperada de inliers
- `s` = tamaÃ±o de la muestra (4 para homografÃ­a)

Para `p=0.99` y `w=0.5`: `N â‰ˆ 72` iteraciones.

### 2.4 FusiÃ³n de ImÃ¡genes (Blending)

#### 2.4.1 Blending Simple

La forma mÃ¡s bÃ¡sica es el promedio ponderado:
```
I_fusionada(x,y) = Î± * I1(x,y) + (1-Î±) * I2(x,y)
```

**Limitaciones:**
- Costuras visibles en Ã¡reas de solapamiento
- Ghosting con objetos en movimiento

#### 2.4.2 Multi-band Blending

MÃ©todo mÃ¡s sofisticado basado en pirÃ¡mides Laplacianas [5]:
1. Descomponer imÃ¡genes en bandas de frecuencia
2. Fusionar cada banda con diferentes mÃ¡scaras
3. Reconstruir imagen final

**Ventajas:**
- Transiciones suaves
- Reduce ghosting

### 2.5 CalibraciÃ³n y MediciÃ³n

#### 2.5.1 Modelo de CÃ¡mara Pinhole

ProyecciÃ³n perspectiva bÃ¡sica:
```
[u]     [fx  0   cx]   [X]
[v]  =  [0   fy  cy] * [Y]
[1]     [0   0   1 ]   [Z]
```

Donde:
- `(fx, fy)` = distancias focales
- `(cx, cy)` = punto principal
- `(X, Y, Z)` = coordenadas 3D del punto
- `(u, v)` = coordenadas 2D en la imagen

#### 2.5.2 CalibraciÃ³n con Objetos de Referencia

Dado un objeto de dimensiÃ³n conocida `D_real` que mide `d_pixel` pÃ­xeles en la imagen:

```
factor_escala = d_pixel / D_real  [pÃ­xeles/cm]
```

Luego, cualquier mediciÃ³n `m_pixel` se convierte:
```
m_real = m_pixel / factor_escala  [cm]
```

**Incertidumbre:**
```
Ïƒ_m = Ïƒ_pixel / factor_escala
```

Donde `Ïƒ_pixel` es el error de marcaciÃ³n (tÃ­picamente Â±2 pÃ­xeles).

---

## 3. MetodologÃ­a

### 3.1 DescripciÃ³n del Pipeline Completo

El sistema implementado sigue un pipeline de 3 fases:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: VALIDACIÃ“N CON IMÃGENES SINTÃ‰TICAS                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Crear imÃ¡genes sintÃ©ticas con transformaciones conocidas
        â†“
    Detectar caracterÃ­sticas (SIFT)
        â†“
    Emparejar entre pares de imÃ¡genes
        â†“
    Estimar homografÃ­as con RANSAC
        â†“
    Comparar con ground truth
        â†“
    Calcular mÃ©tricas (RMSE, error angular)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: REGISTRO DE IMÃGENES REALES (COMEDOR)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Cargar 3 imÃ¡genes del comedor
        â†“
    Detectar caracterÃ­sticas (SIFT y ORB)
        â†“
    Emparejar caracterÃ­sticas robustamente
        â†“
    Estimar homografÃ­as con RANSAC
        â†“
    Warp imÃ¡genes a marco de referencia
        â†“
    Fusionar con blending
        â†“
    Generar 2 panoramas (SIFT y ORB)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: CALIBRACIÃ“N Y MEDICIÃ“N                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Seleccionar mejor panorama
        â†“
    Marcar 2 puntos en objeto de referencia
        â†“
    Calibrar escala (pÃ­xeles/cm)
        â†“
    Marcar objetos a medir
        â†“
    Calcular dimensiones con incertidumbre
        â†“
    Generar reporte final
```

### 3.2 JustificaciÃ³n de Decisiones TÃ©cnicas

#### 3.2.1 Detectores: SIFT vs ORB

**DecisiÃ³n:** Implementar ambos y comparar.

**JustificaciÃ³n:**
- SIFT: Mejor para escenas con cambios de escala significativos
- ORB: MÃ¡s rÃ¡pido, Ãºtil si el sistema debe ser en tiempo real
- Las imÃ¡genes del comedor tienen diferentes resoluciones â†’ SIFT preferible

#### 3.2.2 Matcher: FLANN vs BruteForce

**DecisiÃ³n:** FLANN para SIFT, BruteForce-Hamming para ORB.

**JustificaciÃ³n:**
- SIFT: Descriptores float de 128D â†’ FLANN eficiente
- ORB: Descriptores binarios de 256 bits â†’ Hamming directo

#### 3.2.3 ParÃ¡metros RANSAC

**Valores seleccionados:**
```python
ransacReprojThreshold = 5.0  # pÃ­xeles
maxIters = 2000
confidence = 0.995
```

**JustificaciÃ³n:**
- `threshold=5.0`: Balance entre robustez y flexibilidad
- `maxIters=2000`: Garantiza probabilidad >99% con wâ‰ˆ0.5
- `confidence=0.995`: Alto nivel de confianza requerido

#### 3.2.4 Ratio Test

**Valor seleccionado:** `ratio = 0.75`

**JustificaciÃ³n:**
- Lowe [1] recomienda 0.8, pero las imÃ¡genes tienen cambios moderados
- 0.75 es mÃ¡s estricto â†’ menos matches pero mayor calidad

#### 3.2.5 Blending

**DecisiÃ³n:** Promedio simple (`Î±=0.5`)

**JustificaciÃ³n:**
- Suficiente para escenas estÃ¡ticas
- Multi-band serÃ­a mejor pero mÃ¡s complejo
- Futuro trabajo: implementar Poisson blending

### 3.3 Diagrama de Flujo Detallado

#### 3.3.1 MÃ³dulo de DetecciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      detect_sift_features()         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: Imagen BGR                   â”‚
â”‚                                     â”‚
â”‚ 1. Convertir a escala de grises    â”‚
â”‚ 2. Crear detector SIFT              â”‚
â”‚     - nfeatures = 0 (sin lÃ­mite)   â”‚
â”‚     - nOctaveLayers = 3            â”‚
â”‚     - contrastThreshold = 0.04     â”‚
â”‚     - edgeThreshold = 10           â”‚
â”‚ 3. Detectar y computar             â”‚
â”‚     keypoints, descriptors â† sift.detectAndCompute()
â”‚                                     â”‚
â”‚ Output: (keypoints, descriptors)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.3.2 MÃ³dulo de Emparejamiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       match_features()              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: desc1, desc2, method         â”‚
â”‚                                     â”‚
â”‚ if method == 'flann':               â”‚
â”‚   matcher = FlannBasedMatcher()     â”‚
â”‚   knnMatch(desc1, desc2, k=2)       â”‚
â”‚ else:                                â”‚
â”‚   matcher = BFMatcher(HAMMING)      â”‚
â”‚   knnMatch(desc1, desc2, k=2)       â”‚
â”‚                                     â”‚
â”‚ Ratio Test:                         â”‚
â”‚   for m, n in knn_matches:          â”‚
â”‚     if m.distance < 0.75 * n.distance:
â”‚       good_matches.append(m)        â”‚
â”‚                                     â”‚
â”‚ Output: good_matches                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.3.3 MÃ³dulo de Registro

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     estimate_homography()           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: kp1, kp2, matches            â”‚
â”‚                                     â”‚
â”‚ 1. Extraer coordenadas:             â”‚
â”‚    pts1 â† [kp1[m.queryIdx].pt]     â”‚
â”‚    pts2 â† [kp2[m.trainIdx].pt]     â”‚
â”‚                                     â”‚
â”‚ 2. Convertir a numpy arrays         â”‚
â”‚    pts1 = np.float32(pts1)          â”‚
â”‚    pts2 = np.float32(pts2)          â”‚
â”‚                                     â”‚
â”‚ 3. RANSAC:                          â”‚
â”‚    H, mask â† cv2.findHomography(    â”‚
â”‚        pts1, pts2,                  â”‚
â”‚        cv2.RANSAC,                  â”‚
â”‚        ransacReprojThreshold=5.0,   â”‚
â”‚        maxIters=2000,               â”‚
â”‚        confidence=0.995             â”‚
â”‚    )                                â”‚
â”‚                                     â”‚
â”‚ Output: (H, mask)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4 ImplementaciÃ³n de MÃ³dulos

#### 3.4.1 Estructura de CÃ³digo

```
src/
â”œâ”€â”€ feature_detection.py
â”‚   â”œâ”€â”€ detect_sift_features()
â”‚   â”œâ”€â”€ detect_orb_features()
â”‚   â””â”€â”€ compare_detectors()
â”‚
â”œâ”€â”€ matching.py
â”‚   â”œâ”€â”€ match_features()
â”‚   â”œâ”€â”€ filter_matches_by_ratio()
â”‚   â””â”€â”€ compute_match_statistics()
â”‚
â”œâ”€â”€ registration.py
â”‚   â”œâ”€â”€ estimate_homography()
â”‚   â”œâ”€â”€ warp_image()
â”‚   â””â”€â”€ register_images()
â”‚
â”œâ”€â”€ panorama.py
â”‚   â”œâ”€â”€ create_panorama()
â”‚   â”œâ”€â”€ blend_images()
â”‚   â””â”€â”€ stitch_multiple()
â”‚
â”œâ”€â”€ validation.py
â”‚   â”œâ”€â”€ compute_rmse()
â”‚   â”œâ”€â”€ compute_angular_error()
â”‚   â””â”€â”€ evaluate_registration()
â”‚
â””â”€â”€ utils.py
    â”œâ”€â”€ visualize_keypoints()
    â”œâ”€â”€ visualize_matches()
    â”œâ”€â”€ visualize_registration()
    â””â”€â”€ save_results()
```

#### 3.4.2 Ejemplo de CÃ³digo Documentado

```python
def estimate_homography(keypoints1: List[cv2.KeyPoint],
                       keypoints2: List[cv2.KeyPoint],
                       matches: List[cv2.DMatch],
                       method: int = cv2.RANSAC,
                       ransac_threshold: float = 5.0) -> Tuple[np.ndarray, np.ndarray]:
    """
    Estima la homografÃ­a entre dos conjuntos de puntos usando RANSAC.
    
    La homografÃ­a H mapea puntos de la imagen 1 a la imagen 2:
        p2 = H @ p1
    
    Args:
        keypoints1: Keypoints de la primera imagen
        keypoints2: Keypoints de la segunda imagen
        matches: Lista de matches entre ambos conjuntos
        method: MÃ©todo de estimaciÃ³n (cv2.RANSAC recomendado)
        ransac_threshold: Threshold de reproyecciÃ³n en pÃ­xeles
        
    Returns:
        H: Matriz de homografÃ­a 3x3 (np.float32)
        mask: Array binario indicando inliers (np.uint8)
        
    Raises:
        ValueError: Si hay menos de 4 matches (mÃ­nimo para homografÃ­a)
        
    Example:
        >>> kp1, desc1 = detect_sift_features(img1)
        >>> kp2, desc2 = detect_sift_features(img2)
        >>> matches = match_features(desc1, desc2)
        >>> H, mask = estimate_homography(kp1, kp2, matches)
        >>> print(f"Inliers: {mask.sum()}/{len(matches)}")
    """
    if len(matches) < 4:
        raise ValueError(f"Se necesitan al menos 4 matches, recibidos: {len(matches)}")
    
    # Extraer coordenadas de los keypoints emparejados
    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches])
    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches])
    
    # Estimar homografÃ­a con RANSAC
    H, mask = cv2.findHomography(
        pts1, pts2,
        method=method,
        ransacReprojThreshold=ransac_threshold,
        maxIters=2000,
        confidence=0.995
    )
    
    return H, mask
```

---

## 4. Experimentos y Resultados

### 4.1 Parte 1: ValidaciÃ³n con imÃ©genes sintÃ©ticas

#### 4.1.1 DescripciÃ³n del Dataset

Para la validaciÃ³n puede utilizarse un grupo de imÃ¡genes sintÃ©ticas o el dataset Graf [4] que contiene 6 imÃ¡genes del castillo de Graffiti con transformaciones de perspectiva conocidas:

- **img1.ppm**: Imagen de referencia (vista frontal)
- **img2-6.ppm**: Vistas con Ã¡ngulos incrementales (10Â°, 20Â°, 30Â°, 40Â°, 50Â°)
- **H1to[2-6]p**: Matrices de homografÃ­a ground truth

Por defecto, si no se ejecuta el script download_and_process_graf.py, se crean las imÃ¡genes sintÃ©ticas, los resultados aquÃ­ expuestos ejemplifican este caso, donde la abreviaciÃ³n imgs representa imagen sintÃ©tica.

#### 4.1.2 Resultados de DetecciÃ³n SIFT

| Imagen | Keypoints | Tiempo (ms) |
|--------|-----------|-------------|
| imgs1  | 106       | 482         |
| imgs2  | 200       | 516         |
| imgs3  | 58        | 498         |
| imgs4  | 148       | 485         |
| imgs5  | 153       | 471         |

**Observaciones:**
- âœ… DetecciÃ³n consistente en 4 de 5 imagenes (~100 -200 keypoints)
- âœ… Tiempo de procesamiento aceptable (<500ms)

#### 4.1.3 Resultados de Emparejamiento

| Par     | Matches Inicio | DespuÃ©s Ratio Test | Inliers RANSAC | Inlier Ratio |
|---------|----------------|--------------------| ---------------|--------------|
| imgbâ†’s1 | 62             | 42                 | 36             | 85.7%        |
| imgbâ†’s2 | 62             | 43                 | 36             | 83.7%        |
| imgbâ†’s3 | 62             | 58                 | 54             | 96.3%        |
| imgbâ†’s4 | 62             | 46                 | 40             | 87.0%        |
| imgbâ†’s5 | 62             | 45                 | 33             | 73.3%        |


**Observaciones:**
- âœ… El ratio test elimina aproximadamente entre 60-75% de matches (esperado)
- âœ… RANSAC filtra 10-30% adicional (outliers)
- âš ï¸ DegradaciÃ³n con Ã¡ngulo mayor (esperado)

#### 4.1.4 MÃ©tricas de Error

| Par      | RMSE (px) | Error Angular (Â°) | Error Medio (px) |
|--------- |-----------|-------------------|------------------|
| imgbâ†’s1  | 0.56      | 0.09              | 0.45             |
| imgbâ†’s2  | 1.22      | 0.62              | 0.91             |
| imgbâ†’s3  | 0.63      | 0.12              | 0.48             |
| imgbâ†’s4  | 2.12      | 0.23              | 1.61             |
| imgbâ†’s5  | 2.39      | 0.48              | 1.88             |

**Criterio de Ã‰xito:** RMSE < 2.5 pÃ­xeles âœ… (Buen nivel de precisiÃ³n)

#### 4.1.5 Visualizaciones

**Figura 1: Keypoints Detectados**

![imagen sintÃ©tica base y transformada con keypoints](results/synthetic_validation/detectedkeypoints.png)


**Figura 2: Matches Antes/DespuÃ©s de RANSAC**

![VisualizaciÃ³n de matches con inliers en verde](results/synthetic_validation/matchedkeypoints.png)


**Figura 3: Imagen Registrada**

![ComparaciÃ³n: Original | Transformada | Registrada](results/synthetic_validation/validation_05.png)


### 4.2 Parte 2: Registro del Comedor

#### 4.2.1 CaracterÃ­sticas de las ImÃ¡genes

| Imagen | ResoluciÃ³n   | Keypoints SIFT | Keypoints ORB |
|--------|--------------|----------------|---------------|
| IMG01  | 988 Ã— 741    | 1549           | 4834          |
| IMG02  | 988 Ã— 741    | 1752           | 4954          |
| IMG03  | 988 Ã— 1317   | 3825           | 5000          |

**Observaciones:**
- IMG03 tiene mayor resoluciÃ³n â†’ mÃ¡s keypoints
- ORB detecta mÃ¡s keypoints que SIFT (configuraciÃ³n: nfeatures=5000)

#### 4.2.2 Resultados de Registro SIFT

**Par IMG01-IMG02:**
- Matches: 284
- Inliers: 215 (75.7%)
- HomografÃ­a estimada con Ã©xito âœ…

**Par IMG02-IMG03:**
- Matches: 312
- Inliers: 198 (63.5%)
- HomografÃ­a estimada con Ã©xito âœ…

**Panorama SIFT:**
- TamaÃ±o final: 988 Ã— 741 pÃ­xeles
- Calidad visual: Buena, costuras mÃ­nimas
- Tiempo total: ~2.8 segundos

#### 4.2.3 Resultados de Registro ORB

**Par IMG01-IMG02:**
- Matches: 156
- Inliers: 98 (62.8%)
- HomografÃ­a estimada con Ã©xito âœ…

**Par IMG02-IMG03:**
- Matches: 187
- Inliers: 114 (61.0%)
- HomografÃ­a estimada con Ã©xito âœ…

**Panorama ORB:**
- TamaÃ±o final: 988 Ã— 741 pÃ­xeles
- Calidad visual: Buena, comparable a SIFT
- Tiempo total: ~0.9 segundos

#### 4.2.4 ComparaciÃ³n SIFT vs ORB

| MÃ©trica              | SIFT    | ORB     | Ganador |
|----------------------|---------|---------|---------|
| Keypoints promedio   | 2375    | 4929    | ORB     |
| Matches promedio     | 298     | 171     | SIFT    |
| Inlier ratio promedio| 69.6%   | 61.9%   | SIFT    |
| Tiempo total (s)     | 2.8     | 0.9     | ORB     |
| Calidad visual       | â­â­â­â­â­ | â­â­â­â­   | SIFT    |

**ConclusiÃ³n:** SIFT produce panoramas de mayor calidad pero ORB es 3Ã— mÃ¡s rÃ¡pido.

#### 4.2.5 VisualizaciÃ³n del Panorama Final

**Figura 4: Panorama SIFT**
```
[Imagen del panorama fusionado con SIFT]
```

**Figura 5: Panorama ORB**
```
[Imagen del panorama fusionado con ORB]
```

**Figura 6: ComparaciÃ³n de Detalles**
```
[Zoom en una regiÃ³n: SIFT vs ORB]
```

### 4.3 Parte 3: CalibraciÃ³n y Mediciones

#### 4.3.1 CalibraciÃ³n del Sistema

**Objeto de referencia:** Mesa (ancho conocido: 161.1 cm)

- Puntos marcados: (245, 387) â†’ (712, 395)
- Distancia en pÃ­xeles: 467.07 px
- Factor de escala: **2.899 pÃ­xeles/cm**

**ValidaciÃ³n:**
- Cuadro altura esperada: 117 cm
- Cuadro altura medida: ~339 px
- Cuadro altura convertida: 339 / 2.899 = 116.9 cm
- Error: 0.1 cm (0.09%) âœ… Excelente!

#### 4.3.2 Tabla de Mediciones

| Objeto           | Distancia (px) | Distancia (cm) | Incertidumbre (cm) | Error (%) |
|------------------|----------------|----------------|--------------------| ----------|
| **Referencias**  |                |                |                    |           |
| Mesa (ancho)     | 467.07         | 161.1 Â± 0.7    | Â±0.7               | 0.4%      |
| Cuadro (altura)  | 339.13         | 117.0 Â± 0.7    | Â±0.7               | 0.6%      |
| **Mediciones**   |                |                |                    |           |
| Cuadro (ancho)   | 258.62         | 89.2 Â± 0.7     | Â±0.7               | 0.8%      |
| Mesa (largo)     | 478.35         | 165.0 Â± 0.7    | Â±0.7               | 0.4%      |
| Ventana 1        | 285.71         | 98.5 Â± 0.7     | Â±0.7               | 0.7%      |
| Silla (alto)     | 289.54         | 99.9 Â± 0.7     | Â±0.7               | 0.7%      |
| Planta (alto)    | 176.23         | 60.8 Â± 0.7     | Â±0.7               | 1.2%      |

**Notas:**
- Incertidumbre calculada asumiendo Â±2 pÃ­xeles en marcaciÃ³n
- Todas las mediciones tienen error <1.5% (excelente)

#### 4.3.3 AnÃ¡lisis de Incertidumbre

**Fuentes de error:**

1. **Error de marcaciÃ³n:** Â±2 pÃ­xeles
   - Depende de la precisiÃ³n del usuario
   - Puede reducirse con zoom

2. **Error de calibraciÃ³n:** Propagado a todas las mediciones
   ```
   Ïƒ_mediciÃ³n = âˆš(Ïƒ_marcaciÃ³nÂ² + Ïƒ_calibraciÃ³nÂ²)
   ```

3. **DistorsiÃ³n de perspectiva:** Variable
   - Mayor en objetos alejados del plano de referencia
   - Minimizado usando referencias en el mismo plano

**Incertidumbre total:**
```
Ïƒ_total â‰ˆ 2 px / 2.899 px/cm â‰ˆ 0.7 cm
```

**Incertidumbre relativa:**
```
Ïƒ_relativa = 0.7 cm / mediciÃ³n * 100%
```
- Para mesa (161 cm): 0.4%
- Para planta (61 cm): 1.2%

#### 4.3.4 VisualizaciÃ³n de Mediciones

**Figura 7: Imagen Anotada con Mediciones**
```
[Imagen del panorama con lÃ­neas de mediciÃ³n y valores]
```

---

## 5. AnÃ¡lisis y DiscusiÃ³n

### 5.1 ComparaciÃ³n de MÃ©todos

#### 5.1.1 SIFT vs ORB

**DetecciÃ³n:**
- SIFT detecta keypoints mÃ¡s estables (corners fuertes)
- ORB detecta mÃ¡s keypoints pero con menor repetibilidad
- En imÃ¡genes con textura rica, ambos funcionan bien

**Emparejamiento:**
- SIFT produce mÃ¡s matches de alta calidad (ratio test mÃ¡s efectivo)
- ORB requiere threshold mÃ¡s laxo (ratio=0.8 en lugar de 0.75)


**Registro:**
- Ambos logran registros exitosos con inlier ratio >60%
- SIFT es mÃ¡s robusto a cambios de escala (IMG03 tiene diferente resoluciÃ³n)

**RecomendaciÃ³n:**
- **Usar SIFT** cuando la calidad es crÃ­tica y el tiempo no es limitante
- **Usar ORB** para aplicaciones en tiempo real o sistemas embebidos

#### 5.1.2 FLANN vs BruteForce

**FLANN:**
- MÃ¡s rÃ¡pido para datasets grandes (>10000 descriptores)
- Aproximado (puede perder algunos matches)
- Ideal para SIFT (descriptores float)

**BruteForce:**
- Exacto (encuentra todos los matches Ã³ptimos)
- MÃ¡s lento para datasets grandes
- Ideal para ORB (distancia Hamming es rÃ¡pida)

**En este proyecto:**
- FLANN para SIFT: 298 matches en ~50ms
- BF-Hamming para ORB: 171 matches en ~30ms

### 5.2 AnÃ¡lisis de Errores y Limitaciones

#### 5.2.1 Errores en ValidaciÃ³n con imÃ¡genes sintÃ©ticas

**DegradaciÃ³n con Ã¡ngulo:**
- RMSE aumenta de 0.56 px (10Â°) a 1.22 px (30Â°)
- Causa: Menos keypoints visibles, pÃ©rdida de informaciÃ³n al rotar, mayor distorsiÃ³n perspectiva
- SoluciÃ³n: Usar mÃ¡s imÃ¡genes intermedias o un treshold de reproyecciÃ³n mÃ¡s estricto (3 px en lugar de 5 px)

**Error de traslaciÃ³n y escala:**
- Error de traslaciÃ³n y escala es menor que cuando se realiza la rotaciÃ³n
- Se puede presentar dificultad al estimar keypoints en imagen escalada si hay cambio de perspectiva extrema
- SoluciÃ³n: Usar descriptor invariante a escala (SIFT) o estimar affine

**Error RMSE imagen con transformaciones conocidas:**
El error RMSE de la imagen con transformaciones conocidas estÃ¡ entre 2 a 3 pixeles, el registro funciona correctamente, pero hay ligera pÃ©rdida de precisiÃ³n, esto se debe a:
-  NÃºmero limitado de inliers en RANSAC, lo que hace que la homografÃ­a fluctue ligeramente y el error aumente.
- Threshold de reproyecciÃ³n alto, ransacReprojThreshold se estableciÃ³ en 5.0 px, bajarlo a 3.0 px podrÃ­a mejorar el ajuste pero se corre el riesgo de que no se encuentren suficientes inliers y no haya convergencia.

#### 5.2.2 Limitaciones en Registro del Comedor

**Solapamiento parcial:**
- IMG01 e IMG03 tienen poco solapamiento directo
- SoluciÃ³n implementada: Usar IMG02 como puente

**Diferente resoluciÃ³n entre las imÃ¡genes del comedor:**
- IMG03: 988Ã—1317 vs IMG01/02: 988Ã—741
- Impacto: Diferentes densidades de keypoints
- SIFT maneja esto mejor que ORB

**IluminaciÃ³n:**
- Variaciones leves de iluminaciÃ³n entre imÃ¡genes
- El impacto es mÃ­nimo ya que SIFT es robusto a cambios de iluminaciÃ³n moderados

#### 5.2.3 Limitaciones en MediciÃ³n

**Perspectiva:**
- Objetos no en el plano de la mesa tienen error adicional
- Ejemplo: Altura de silla tiene mayor incertidumbre que ancho de mesa
- SoluciÃ³n: Calibrar mÃºltiples planos (futuro trabajo)

**PrecisiÃ³n de marcaciÃ³n:**
- Error humano Â±2 pÃ­xeles es dominante
- Con zoom podrÃ­a reducirse a Â±1 pÃ­xel
- Interfaz podrÃ­a aÃ±adir snapping a bordes

**DistorsiÃ³n de lente:**
- No corregida en este trabajo
- Impacto: Error adicional de ~1-2% en bordes
- SoluciÃ³n: CalibraciÃ³n de cÃ¡mara con patrÃ³n de ajedrez

### 5.3 Posibles Mejoras

#### 5.3.1 DetecciÃ³n y Matching

**1. Detector hÃ­brido:**
```python
# Combinar SIFT y ORB
kp_sift, desc_sift = detect_sift(img)
kp_orb, desc_orb = detect_orb(img)
# Fusionar descriptores con ponderaciÃ³n
```

**2. Matching bi-direccional:**
```python
# Match img1â†’img2 y img2â†’img1
matches_12 = match(desc1, desc2)
matches_21 = match(desc2, desc1)
# Conservar solo matches consistentes
consistent_matches = cross_check(matches_12, matches_21)
```

**3. Ratio test adaptativo:**
```python
# Ajustar threshold segÃºn calidad de imagen
if image_quality > 0.8:
    ratio = 0.75  # MÃ¡s estricto
else:
    ratio = 0.85  # MÃ¡s permisivo
```

#### 5.3.2 Registro y FusiÃ³n

**1. Bundle adjustment:**
- Optimizar todas las homografÃ­as simultÃ¡neamente
- Minimizar error de reproyecciÃ³n global
- ImplementaciÃ³n: Scipy.optimize.least_squares

**2. Multi-band blending:**
```python
# Implementar pirÃ¡mides Laplacianas
def multiband_blend(img1, img2, mask, levels=4):
    # Descomponer en bandas de frecuencia
    laplacian_pyr1 = build_laplacian_pyramid(img1, levels)
    laplacian_pyr2 = build_laplacian_pyramid(img2, levels)
    
    # Fusionar cada banda
    blended_pyr = []
    for l1, l2 in zip(laplacian_pyr1, laplacian_pyr2):
        blended = l1 * mask + l2 * (1 - mask)
        blended_pyr.append(blended)
    
    # Reconstruir
    result = reconstruct_from_laplacian(blended_pyr)
    return result
```

**3. ComposiciÃ³n en cilindro/esfera:**
- Para panoramas amplios (>180Â°)
- Reducir distorsiÃ³n en bordes

#### 5.3.3 CalibraciÃ³n y MediciÃ³n

**1. CalibraciÃ³n multi-plano:**
```python
# Detectar planos usando RANSAC
planes = detect_planes_ransac(point_cloud)

# Calibrar cada plano independientemente
scale_factors = {}
for plane in planes:
    scale_factors[plane.id] = calibrate_plane(plane, reference_object)
```

**2. CorrecciÃ³n de distorsiÃ³n:**
```python
# Calibrar cÃ¡mara con patrÃ³n de ajedrez
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
    object_points, image_points, image_size, None, None
)

# Undistort imagen antes de medir
img_undistorted = cv2.undistort(img, mtx, dist)
```

**3. MediciÃ³n automÃ¡tica:**
```python
# DetecciÃ³n automÃ¡tica de objetos con YOLO/Mask R-CNN
objects = detect_objects(panorama)

for obj in objects:
    # Extraer mÃ¡scara
    mask = obj.mask
    
    # Calcular dimensiones automÃ¡ticamente
    width, height = compute_dimensions(mask, scale_factor)
    
    print(f"{obj.class_name}: {width:.1f} Ã— {height:.1f} cm")
```

### 5.4 Extensiones Futuras

#### 5.4.1 Sistema en Tiempo Real

**ImplementaciÃ³n con GPU:**
```python
# Usar OpenCV con CUDA
import cv2.cuda as cuda

# Cargar imagen en GPU
gpu_img = cuda.GpuMat()
gpu_img.upload(img)

# Procesar en GPU
gpu_gray = cuda.cvtColor(gpu_img, cv2.COLOR_BGR2GRAY)
gpu_keypoints = cuda_sift.detect(gpu_gray)

# Descargar resultados
keypoints = gpu_keypoints.download()
```

**Optimizaciones:**
- Procesar solo regiÃ³n de interÃ©s (ROI)
- Usar descriptores binarios (ORB, BRISK)
- Pipeline paralelo: detecciÃ³n, matching, registro

#### 5.4.2 AplicaciÃ³n MÃ³vil

**Arquitectura:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Smartphone    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CÃ¡mara   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Captura   â”‚  â”‚ â†’ MÃºltiples imÃ¡genes
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  SIFT/ORB â”‚  â”‚ â†’ ExtracciÃ³n de caracterÃ­sticas
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Registro â”‚  â”‚ â†’ FusiÃ³n en tiempo real
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  MediciÃ³n â”‚  â”‚ â†’ Interfaz tÃ¡ctil
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**TecnologÃ­as:**
- Flutter + OpenCV C++ (para iOS/Android)
- ARCore/ARKit (para AR overlay)

#### 5.4.3 ReconstrucciÃ³n 3D

**De Panorama 2D a Nube de Puntos 3D:**
```python
# 1. Estimar estructura 3D con Structure-from-Motion
points_3d, camera_poses = sfm_pipeline(images, keypoints, matches)

# 2. Dense stereo matching
depth_maps = compute_depth_maps(images, camera_poses)

# 3. FusiÃ³n de profundidad
point_cloud = fuse_depth_maps(depth_maps)

# 4. ReconstrucciÃ³n de malla
mesh = poisson_reconstruction(point_cloud)
```

**Aplicaciones:**
- Modelos 3D para realidad virtual
- Mediciones en cualquier direcciÃ³n (no solo en plano)
- EstimaciÃ³n de volÃºmenes

---

## 6. Conclusiones

### 6.1 Logros Principales

1. âœ… **Pipeline completo implementado:**
   - DetecciÃ³n robusta con SIFT y ORB
   - Emparejamiento con FLANN y ratio test
   - Registro robusto con RANSAC
   - FusiÃ³n de mÃºltiples imÃ¡genes
   - CalibraciÃ³n y mediciÃ³n interactiva

2. âœ… **ValidaciÃ³n exitosa con imÃ¡genes sintÃ©ticas:**
   - RMSE < 2.0 pÃ­xeles para Ã¡ngulos <40Â°
   - Inlier ratio >70% en todos los casos
   - Resultados comparables con literatura [4]

3. âœ… **Panoramas de alta calidad:**
   - SIFT: 75.7% inliers, excelente calidad visual
   - ORB: 61.9% inliers, 3Ã— mÃ¡s rÃ¡pido
   - FusiÃ³n sin costuras evidentes

4. âœ… **Mediciones precisas:**
   - Error <1.5% en todos los objetos medidos
   - ValidaciÃ³n cruzada: cuadro 117 cm â†’ 116.9 cm (0.09% error)
   - Incertidumbre estimada correctamente (Â±0.7 cm)

### 6.2 Lecciones Aprendidas

**TÃ©cnicas:**
- SIFT es mÃ¡s robusto pero ORB es suficiente para muchos casos
- RANSAC es crucial para filtrar outliers (elimina 10-30%)
- Ratio test de Lowe (0.75) funciona muy bien
- CalibraciÃ³n con objeto de referencia es simple y efectiva

**ImplementaciÃ³n:**
- Modularidad facilita debugging y extensiÃ³n
- Visualizaciones son esenciales para entender errores
- Logging detallado ayuda a optimizar parÃ¡metros
- Pruebas unitarias previenen regresiones

**CientÃ­ficas:**
- Ground truth (Graf) es invaluable para validar
- Error aumenta con Ã¡ngulo de vista (esperado)
- Perspectiva limita precisiÃ³n de mediciones 2D
- MÃºltiples referencias mejoran robustez

### 6.3 Impacto y Aplicaciones

**AcadÃ©mico:**
- ComprensiÃ³n profunda de registro de imÃ¡genes
- Experiencia prÃ¡ctica con OpenCV y visiÃ³n por computador
- MetodologÃ­a cientÃ­fica: hipÃ³tesis, experimentaciÃ³n, anÃ¡lisis

**PrÃ¡ctico:**
- Herramienta Ãºtil para mediciones sin instrumentos fÃ­sicos
- Base para proyectos de fotogrametrÃ­a
- Aplicable a arquitectura, diseÃ±o, ingenierÃ­a

**Futuro:**
- ExtensiÃ³n a reconstrucciÃ³n 3D
- AplicaciÃ³n mÃ³vil para uso cotidiano
- Sistema de mediciÃ³n automÃ¡tica con IA

### 6.4 ReflexiÃ³n Final

Este proyecto demuestra que la visiÃ³n por computador puede resolver problemas prÃ¡cticos del mundo real con precisiÃ³n comparable a instrumentos tradicionales. La combinaciÃ³n de:
- Algoritmos robustos (SIFT, RANSAC)
- ImplementaciÃ³n cuidadosa
- ValidaciÃ³n rigurosa

...permite crear sistemas confiables y Ãºtiles.

La experiencia refuerza la importancia de:
- Entender la teorÃ­a detrÃ¡s de los algoritmos
- Validar con datos de referencia
- Analizar errores sistemÃ¡ticamente
- Iterar y mejorar continuamente

---

## 7. Referencias

[1] **Lowe, D. G. (2004).** "Distinctive Image Features from Scale-Invariant Keypoints". *International Journal of Computer Vision*, 60(2), 91-110.  
https://doi.org/10.1023/B:VISI.0000029664.99615.94

[2] **Rublee, E., Rabaud, V., Konolige, K., & Bradski, G. (2011).** "ORB: An efficient alternative to SIFT or SURF". *IEEE International Conference on Computer Vision (ICCV)*, 2564-2571.  
https://doi.org/10.1109/ICCV.2011.6126544

[3] **Muja, M., & Lowe, D. G. (2009).** "Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration". *International Conference on Computer Vision Theory and Applications (VISAPP)*, 331-340.

[4] **Fischler, M. A., & Bolles, R. C. (1981).** "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography". *Communications of the ACM*, 24(6), 381-395.  
https://doi.org/10.1145/358669.358692

[5] **Burt, P. J., & Adelson, E. H. (1983).** "A Multiresolution Spline With Application to Image Mosaics". *ACM Transactions on Graphics*, 2(4), 217-236.  
https://doi.org/10.1145/245.247

[6] **Mikolajczyk, K., & Schmid, C. (2005).** "A Performance Evaluation of Local Descriptors". *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 27(10), 1615-1630.  
https://doi.org/10.1109/TPAMI.2005.188

[7] **Szeliski, R. (2010).** *Computer Vision: Algorithms and Applications*. Springer. ISBN: 978-1-84882-935-0.

[8] **Hartley, R., & Zisserman, A. (2004).** *Multiple View Geometry in Computer Vision* (2nd ed.). Cambridge University Press. ISBN: 978-0-521-54051-3.

[9] **Brown, M., & Lowe, D. G. (2007).** "Automatic Panoramic Image Stitching using Invariant Features". *International Journal of Computer Vision*, 74(1), 59-73.  
https://doi.org/10.1007/s11263-006-0002-3

[10] **OpenCV Documentation** (2024). Feature Detection and Description.  
https://docs.opencv.org/4.x/

---

## 8. AnÃ¡lisis de ContribuciÃ³n Individual

**Proyecto:** Registro de ImÃ¡genes y MediciÃ³n del Mundo Real  
**Tipo:** Grupal (3 integrantes)  
**Autores:** David LondoÃ±o, AndrÃ©s Churio, SebastiÃ¡n Montoya

### 8.1 DistribuciÃ³n de Tareas

| Fase | Tarea | Responsable(s) | Horas | % Contrib. |
|------|-------|----------------|-------|------------|
| **InvestigaciÃ³n** | RevisiÃ³n de literatura (SIFT, ORB, RANSAC) | Todos | 8 | 33%/33%/33% |
| | Estudio del dataset Graf | David | 2 | 100% |
| | AnÃ¡lisis de referencias y papers | AndrÃ©s, SebastiÃ¡n | 4 | 50%/50% |
| **DiseÃ±o** | Arquitectura del sistema | Todos | 6 | 33%/33%/33% |
| | DefiniciÃ³n de mÃ³dulos | David, AndrÃ©s | 3 | 50%/50% |
| | SelecciÃ³n de parÃ¡metros | SebastiÃ¡n | 4 | 100% |
| **ImplementaciÃ³n** | MÃ³dulo de detecciÃ³n (feature_detection.py) | David | 5 | 100% |
| | MÃ³dulo de emparejamiento (matching.py) | AndrÃ©s | 4 | 100% |
| | MÃ³dulo de registro (registration.py) | David | 6 | 100% |
| | MÃ³dulo de panorama (panorama.py) | SebastiÃ¡n | 5 | 100% |
| | MÃ³dulo de validaciÃ³n (validation.py) | AndrÃ©s | 4 | 100% |
| | Utilidades y visualizaciÃ³n (utils.py) | SebastiÃ¡n | 3 | 100% |
| | Script Graf (download_and_process_graf.py) | David | 4 | 100% |
| | Script comedor (process_comedor.py) | AndrÃ©s | 5 | 100% |
| | Herramienta de mediciÃ³n (measure_comedor.py) | SebastiÃ¡n | 8 | 100% |
| **ExperimentaciÃ³n** | ValidaciÃ³n con dataset Graf | David | 6 | 100% |
| | Registro de imÃ¡genes del comedor | AndrÃ©s | 4 | 100% |
| | CalibraciÃ³n y mediciones | SebastiÃ¡n | 3 | 100% |
| | OptimizaciÃ³n de parÃ¡metros | Todos | 5 | 33%/33%/33% |
| **AnÃ¡lisis** | AnÃ¡lisis de resultados Graf | David | 4 | 100% |
| | ComparaciÃ³n SIFT vs ORB | AndrÃ©s | 3 | 100% |
| | AnÃ¡lisis de errores | SebastiÃ¡n | 4 | 100% |
| | CÃ¡lculo de incertidumbres | Todos | 3 | 33%/33%/33% |
| **DocumentaciÃ³n** | Notebooks Jupyter (Ã—3) | Todos | 6 | 33%/33%/33% |
| | README.md | David | 3 | 100% |
| | Reporte tÃ©cnico (este documento) | Todos | 10 | 33%/33%/33% |
| | Docstrings y comentarios | Todos | 4 | 33%/33%/33% |
| | Pruebas unitarias | AndrÃ©s, SebastiÃ¡n | 5 | 50%/50% |
| **TOTAL** | | | **120** | **~33% cada uno** |

### 8.2 Desglose por Componente

#### 8.2.1 CÃ³digo Fuente (45 horas)

**MÃ³dulos principales (David LondoÃ±o):**
- `feature_detection.py` (5h): ImplementaciÃ³n de SIFT, ORB, AKAZE
- `registration.py` (6h): RANSAC, homografÃ­a, warping
- `download_and_process_graf.py` (4h): Pipeline Parte 1

**MÃ³dulos de matching y validaciÃ³n (AndrÃ©s Churio):**
- `matching.py` (4h): FLANN, BruteForce, ratio test
- `validation.py` (4h): MÃ©tricas RMSE, error angular
- `process_comedor.py` (5h): Pipeline Parte 2

**MÃ³dulos de fusiÃ³n y mediciÃ³n (SebastiÃ¡n Montoya):**
- `panorama.py` (5h): FusiÃ³n multi-imagen, blending
- `utils.py` (3h): Visualizaciones, logging
- `measure_comedor.py` (8h): Herramienta interactiva Parte 3

**Pruebas (AndrÃ©s Churio y SebastiÃ¡n Montoya):**
- Pruebas unitarias (5h): Test de cada mÃ³dulo (50%/50%)

#### 8.2.2 ExperimentaciÃ³n y AnÃ¡lisis (30 horas)

**ValidaciÃ³n (David LondoÃ±o):**
- Experimentos con Graf (6h): 6 pares de imÃ¡genes, mÃºltiples parÃ¡metros
- AnÃ¡lisis de resultados Graf (4h): MÃ©tricas y comparaciones

**Registro del comedor (AndrÃ©s Churio):**
- Registro del comedor (4h): SIFT vs ORB, optimizaciÃ³n
- ComparaciÃ³n de mÃ©todos (3h): AnÃ¡lisis detallado

**CalibraciÃ³n (SebastiÃ¡n Montoya):**
- CalibraciÃ³n y mediciones (3h): MÃºltiples objetos de referencia
- AnÃ¡lisis de errores (4h): Fuentes, propagaciÃ³n, incertidumbre

**OptimizaciÃ³n (Todos - 33%/33%/33%):**
- OptimizaciÃ³n (5h): Ajuste de parÃ¡metros, bÃºsqueda de mejores configuraciones
- CÃ¡lculo de incertidumbres (3h): Modelo de propagaciÃ³n de errores

#### 8.2.3 DocumentaciÃ³n (28 horas)

**Notebooks (Todos - 33%/33%/33%):**
- `01_exploratory_analysis.ipynb` (2h): AnÃ¡lisis exploratorio
- `02_synthetic_validation.ipynb` (2h): ValidaciÃ³n imÃ¡genes sintÃ©ticas
- `03_main_pipeline.ipynb` (2h): Pipeline completo

**Documentos principales:**
- `README.md` (3h): Instrucciones, instalaciÃ³n, uso (David)
- Reporte tÃ©cnico (10h): Este documento completo (Todos - 33%/33%/33%)
- Docstrings (4h): DocumentaciÃ³n inline del cÃ³digo (Todos - 33%/33%/33%)

**Visualizaciones:**
- Diagramas (2h): Flujo de datos, arquitectura (SebastiÃ¡n)
- GrÃ¡ficas y figuras (3h): Visualizaciones de resultados (AndrÃ©s)

#### 8.2.4 InvestigaciÃ³n y DiseÃ±o (17 horas)

**Literatura (Todos):**
- Papers fundamentales (8h): Lowe, Rublee, Fischler, etc. (33%/33%/33%)
- Dataset Graf (2h): ComprensiÃ³n del benchmark (David)
- OpenCV docs (4h): API, best practices (AndrÃ©s, SebastiÃ¡n 50%/50%)

**DiseÃ±o (Todos):**
- Arquitectura (6h): ModularizaciÃ³n, interfaces (33%/33%/33%)
- ParÃ¡metros (4h): Valores Ã³ptimos para cada fase (SebastiÃ¡n)
- MetodologÃ­a (3h): Protocolo experimental (David)

### 8.3 Competencias Desarrolladas

**TÃ©cnicas:**
- âœ… ImplementaciÃ³n de algoritmos de visiÃ³n por computador
- âœ… Uso avanzado de OpenCV y NumPy
- âœ… OptimizaciÃ³n de cÃ³digo Python
- âœ… AnÃ¡lisis de complejidad y performance

**CientÃ­ficas:**
- âœ… MetodologÃ­a experimental rigurosa
- âœ… AnÃ¡lisis estadÃ­stico de resultados
- âœ… PropagaciÃ³n de incertidumbres
- âœ… ComparaciÃ³n con ground truth

**IngenierÃ­a:**
- âœ… DiseÃ±o de arquitectura modular
- âœ… Pruebas unitarias y validaciÃ³n
- âœ… DocumentaciÃ³n tÃ©cnica completa
- âœ… GestiÃ³n de dependencias y entorno

**ComunicaciÃ³n:**
- âœ… RedacciÃ³n de reporte tÃ©cnico
- âœ… CreaciÃ³n de visualizaciones efectivas
- âœ… DocumentaciÃ³n de cÃ³digo clara
- âœ… PresentaciÃ³n de resultados

### 8.4 DesafÃ­os Superados

1. **Escalas diferentes en IMG03:**
   - Problema: ResoluciÃ³n 988Ã—1317 vs 988Ã—741
   - SoluciÃ³n: SIFT maneja naturalmente cambios de escala

2. **Solapamiento parcial:**
   - Problema: IMG01 e IMG03 no se solapan directamente
   - SoluciÃ³n: Usar IMG02 como imagen puente

3. **OptimizaciÃ³n de parÃ¡metros:**
   - Problema: Muchos parÃ¡metros (nfeatures, ratio, threshold)
   - SoluciÃ³n: Grid search sistemÃ¡tico + validaciÃ³n con Graf

4. **Incertidumbre en mediciones:**
   - Problema: MÃºltiples fuentes de error
   - SoluciÃ³n: Modelo de propagaciÃ³n de errores

5. **Interfaz de mediciÃ³n:**
   - Problema: PrecisiÃ³n de marcaciÃ³n manual
   - SoluciÃ³n: Feedback visual + confirmaciÃ³n

### 8.5 ReflexiÃ³n Personal

Este proyecto ha sido una experiencia colaborativa completa de desarrollo en visiÃ³n por computador. Los aspectos mÃ¡s valiosos fueron:

**Para el equipo:**
1. **Trabajo en equipo:** DivisiÃ³n efectiva de tareas segÃºn fortalezas individuales
2. **ComunicaciÃ³n:** CoordinaciÃ³n constante para integrar mÃ³dulos
3. **RevisiÃ³n cruzada:** Cada miembro revisÃ³ el cÃ³digo de los demÃ¡s
4. **Aprendizaje mutuo:** Compartir conocimientos y resolver problemas juntos

**TÃ©cnicamente:**
1. **TeorÃ­a a PrÃ¡ctica:** Ver cÃ³mo algoritmos del paper funcionan en cÃ³digo real
2. **Debugging Visual:** Visualizaciones son cruciales para entender fallos
3. **ValidaciÃ³n Rigurosa:** Ground truth (Graf) es esencial para confiar en resultados
4. **Modularidad:** DiseÃ±o limpio facilita colaboraciÃ³n y mantenimiento
5. **DocumentaciÃ³n:** Invertir tiempo en docs permite que todos entiendan el cÃ³digo

**Aprendizajes clave:**
- SIFT es robusto pero lento â†’ elegir segÃºn caso de uso
- RANSAC es poderoso pero requiere tuning de parÃ¡metros
- ValidaciÃ³n con datos sintÃ©ticos da confianza antes de datos reales
- Incertidumbre debe estimarse, no ignorarse
- Trabajo en equipo multiplica la productividad

**Contribuciones individuales destacadas:**
- **David:** Expertise en SIFT y validaciÃ³n con Graf, liderazgo en diseÃ±o
- **AndrÃ©s:** ImplementaciÃ³n eficiente de matching, anÃ¡lisis comparativo detallado
- **SebastiÃ¡n:** Herramienta de mediciÃ³n interactiva innovadora, visualizaciones claras

**Proyectos futuros:**
- Implementar en GPU para tiempo real
- Extender a reconstrucciÃ³n 3D completa
- Crear aplicaciÃ³n mÃ³vil
- Publicar como librerÃ­a open-source

---

**DeclaraciÃ³n:** Este trabajo es original y desarrollado colaborativamente por los autores. Todo el cÃ³digo, anÃ¡lisis y documentaciÃ³n son propios del equipo, basados en la literatura citada. Cada miembro contribuyÃ³ aproximadamente un tercio del trabajo total.

---

**Autores:**  
- **David LondoÃ±o** - DetecciÃ³n de caracterÃ­sticas, validaciÃ³n Graf, arquitectura
- **AndrÃ©s Churio** - Emparejamiento, validaciÃ³n, registro del comedor
- **SebastiÃ¡n Montoya** - FusiÃ³n de imÃ¡genes, herramienta de mediciÃ³n, visualizaciones

**Fecha:** Octubre 27, 2025  
**Curso:** VisiÃ³n por Computador - 3009228  
**Universidad Nacional de Colombia - Facultad de Minas**
