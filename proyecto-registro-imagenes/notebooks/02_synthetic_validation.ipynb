{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e773aa",
   "metadata": {},
   "source": [
    "# Validación con Imágenes Sintéticas\n",
    "\n",
    "**Universidad Nacional de Colombia**  \n",
    "**Visión por Computador**  \n",
    "**Trabajo 2: Registro de Imágenes**\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Generar imágenes sintéticas con transformaciones conocidas\n",
    "2. Aplicar el algoritmo de registro\n",
    "3. Recuperar las transformaciones y compararlas con el ground truth\n",
    "4. Calcular métricas de error (RMSE, error angular)\n",
    "5. Validar la precisión del método antes de aplicarlo a imágenes reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Importar módulos del proyecto\n",
    "from feature_detection import detect_sift_features\n",
    "from matching import match_features\n",
    "from registration import estimate_homography, warp_image\n",
    "from utils import (\n",
    "    generate_synthetic_image,\n",
    "    compute_registration_metrics,\n",
    "    visualize_registration,\n",
    "    plot_metrics_table\n",
    ")\n",
    "\n",
    "# Configuración\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f4339",
   "metadata": {},
   "source": [
    "## 1. Cargar Imagen Base\n",
    "\n",
    "Se puede usar una de las imágenes reales como base para generar sintéticas o generar imágenes sintéticas desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar imagen base\n",
    "img_base_path = '../data/original'  # Ajustar según disponibilidad\n",
    "base_images = list(Path(img_base_path).glob('*.jpg')) + list(Path(img_base_path).glob('*.png'))\n",
    "\n",
    "if len(base_images) > 0:\n",
    "    img_base = cv2.imread(str(base_images[0]))\n",
    "    print(f\"✓ Imagen base cargada: {base_images[0].name}\")\n",
    "    print(f\"  Dimensiones: {img_base.shape[1]}x{img_base.shape[0]}\")\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Imagen Base para Validación Sintética')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    # Crear imagen sintética simple si no hay imágenes\n",
    "    print(\"⚠ No hay imágenes en data/original. Creando imagen de prueba...\")\n",
    "    img_base= np.zeros((400, 400), dtype=np.uint8)\n",
    "    cv2.circle(img_base, (200, 200), 80, 255, -1)\n",
    "    cv2.line(img_base, (50, 50), (350, 350), 255, 3)\n",
    "    cv2.rectangle(img_base, (100, 300), (300, 350), 255, -1)\n",
    "    cv2.putText(img_base, \"TEST\", (120, 120), cv2.FONT_HERSHEY_SIMPLEX, 1.3, 255, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246b8f2",
   "metadata": {},
   "source": [
    "## 2. Generar Imágenes Sintéticas\n",
    "\n",
    "Aplicamos transformaciones conocidas: rotación, traslación, escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir transformaciones a probar\n",
    "transformations = [\n",
    "    {'name': 'Rotación 15°', 'rotation': 15, 'translation': (0, 0), 'scale': 1.0},\n",
    "    {'name': 'Rotación 30°', 'rotation': 30, 'translation': (0, 0), 'scale': 1.0},\n",
    "    {'name': 'Traslación (50, 30)', 'rotation': 0, 'translation': (50, 30), 'scale': 1.0},\n",
    "    {'name': 'Escala 1.2x', 'rotation': 0, 'translation': (0, 0), 'scale': 1.2},\n",
    "    {'name': 'Combinada', 'rotation': 20, 'translation': (40, 20), 'scale': 1.1},\n",
    "]\n",
    "\n",
    "# Generar y guardar imágenes sintéticas\n",
    "synthetic_dir = Path('../data/synthetic')\n",
    "synthetic_dir.mkdir(exist_ok=True)\n",
    "\n",
    "synthetic_images = []\n",
    "ground_truth_matrices = []\n",
    "\n",
    "for i, transform in enumerate(transformations):\n",
    "    img_synthetic, H_true = generate_synthetic_image(\n",
    "        img_base,\n",
    "        rotation=transform['rotation'],\n",
    "        translation=transform['translation'],\n",
    "        scale=transform['scale']\n",
    "    )\n",
    "    \n",
    "    synthetic_images.append((transform['name'], img_synthetic))\n",
    "    ground_truth_matrices.append(H_true)\n",
    "    \n",
    "    # Guardar\n",
    "    filename = f\"synthetic_{i+1:02d}.jpg\"\n",
    "    cv2.imwrite(str(synthetic_dir / filename), img_synthetic)\n",
    "    print(f\"✓ Generada: {transform['name']} -> {filename}\")\n",
    "\n",
    "print(f\"\\n✓ Total de imágenes sintéticas generadas: {len(synthetic_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab972b20",
   "metadata": {},
   "source": [
    "## 3. Aplicar Registro y Evaluar\n",
    "\n",
    "Registramos cada imagen sintética y comparamos con el ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar resultados\n",
    "results = []\n",
    "\n",
    "for idx, ((name, img_synthetic), H_true) in enumerate(zip(synthetic_images, ground_truth_matrices)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESANDO: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. Detectar características\n",
    "    kp_base, desc_base = detect_sift_features(img_base)\n",
    "    kp_synthetic, desc_synthetic = detect_sift_features(img_synthetic)\n",
    "    print(f\"  Keypoints: Base={len(kp_base)}, Sintética={len(kp_synthetic)}\")\n",
    "    \n",
    "    # 2. Emparejar\n",
    "    matches = match_features(desc_base, desc_synthetic, method='flann', ratio_test=0.75)\n",
    "    print(f\"  Matches: {len(matches)}\")\n",
    "    \n",
    "    # 3. Estimar homografía\n",
    "    H_estimated, mask = estimate_homography(kp_base, kp_synthetic, matches)\n",
    "    \n",
    "    if H_estimated is not None:\n",
    "        # 4. Aplicar registro\n",
    "        img_registered = warp_image(img_synthetic, np.linalg.inv(H_estimated), img_base.shape[:2])\n",
    "        \n",
    "        # 5. Calcular métricas\n",
    "        metrics = compute_registration_metrics(\n",
    "            H_true, H_estimated,\n",
    "            image_shape=img_base.shape[:2]\n",
    "        )\n",
    "        \n",
    "        print(f\"  RMSE: {metrics['rmse']:.2f} píxeles\")\n",
    "        print(f\"  Error Angular: {metrics['angular_error']:.2f}°\")\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results.append({\n",
    "            'Transformación': name,\n",
    "            'RMSE (px)': metrics['rmse'],\n",
    "            'Error Medio (px)': metrics['mean_error'],\n",
    "            'Error Angular (°)': metrics['angular_error'],\n",
    "            'Matches': len(matches),\n",
    "            'Inliers': int(np.sum(mask)) if mask is not None else 0\n",
    "        })\n",
    "        \n",
    "        # Visualizar\n",
    "        visualize_registration(img_base, img_synthetic, img_registered,\n",
    "                             save_path=f'../results/synthetic_validation/validation_{idx+1:02d}.png')\n",
    "    else:\n",
    "        print(\"  ⚠ Error: No se pudo estimar homografía\")\n",
    "        results.append({\n",
    "            'Transformación': name,\n",
    "            'RMSE (px)': np.nan,\n",
    "            'Error Medio (px)': np.nan,\n",
    "            'Error Angular (°)': np.nan,\n",
    "            'Matches': len(matches),\n",
    "            'Inliers': 0\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f646637",
   "metadata": {},
   "source": [
    "## 4. Tabla de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101dbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA DE RESULTADOS - VALIDACIÓN SINTÉTICA\")\n",
    "print(\"=\"*80)\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "#Crear carpeta para almacenar resultados de metricas\n",
    "output_dir_measurements = \"../results/measurements\"\n",
    "os.makedirs(output_dir_measurements, exist_ok=True)\n",
    "\n",
    "# Guardar metricas como CSV\n",
    "df_results.to_csv(os.path.join(output_dir_measurements, \"synthetic_validation_results.csv\"), index=False)\n",
    "print(\"\\n✓ Resultados guardados en:\", os.path.join(output_dir_measurements, \"synthetic_validation_results.csv\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table_data = df_results.round(2).values.tolist()\n",
    "table = ax.table(cellText=table_data, colLabels=df_results.columns,\n",
    "                loc='center', cellLoc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "for i in range(len(df_results.columns)):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "plt.title('Resultados de Validación con Imágenes Sintéticas', fontsize=14, pad=20)\n",
    "plt.savefig('../results/synthetic_validation/04_validation_table.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc7fdd",
   "metadata": {},
   "source": [
    "## 5. Análisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de análisis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# RMSE por transformación\n",
    "axes[0, 0].bar(range(len(df_results)), df_results['RMSE (px)'], color='steelblue')\n",
    "axes[0, 0].set_xticks(range(len(df_results)))\n",
    "axes[0, 0].set_xticklabels(df_results['Transformación'], rotation=45, ha='right')\n",
    "axes[0, 0].set_ylabel('RMSE (píxeles)')\n",
    "axes[0, 0].set_title('Error RMSE por Transformación')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error Angular\n",
    "axes[0, 1].bar(range(len(df_results)), df_results['Error Angular (°)'], color='coral')\n",
    "axes[0, 1].set_xticks(range(len(df_results)))\n",
    "axes[0, 1].set_xticklabels(df_results['Transformación'], rotation=45, ha='right')\n",
    "axes[0, 1].set_ylabel('Error Angular (°)')\n",
    "axes[0, 1].set_title('Error Angular por Transformación')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Matches e Inliers\n",
    "x = range(len(df_results))\n",
    "width = 0.35\n",
    "axes[1, 0].bar([i - width/2 for i in x], df_results['Matches'], width, label='Matches', color='lightblue')\n",
    "axes[1, 0].bar([i + width/2 for i in x], df_results['Inliers'], width, label='Inliers', color='lightgreen')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(df_results['Transformación'], rotation=45, ha='right')\n",
    "axes[1, 0].set_ylabel('Cantidad')\n",
    "axes[1, 0].set_title('Matches e Inliers por Transformación')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ratio Inliers/Matches\n",
    "ratio = (df_results['Inliers'] / df_results['Matches'] * 100)\n",
    "axes[1, 1].bar(range(len(df_results)), ratio, color='mediumseagreen')\n",
    "axes[1, 1].set_xticks(range(len(df_results)))\n",
    "axes[1, 1].set_xticklabels(df_results['Transformación'], rotation=45, ha='right')\n",
    "axes[1, 1].set_ylabel('Porcentaje (%)')\n",
    "axes[1, 1].set_title('Ratio Inliers/Matches')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/synthetic_validation/05_validation_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca0671d",
   "metadata": {},
   "source": [
    "## 6. Conclusiones\n",
    "\n",
    "**Resumen de la Validación:**\n",
    "\n",
    "1. **Precisión:** El algoritmo logra recuperar transformaciones con RMSE < X píxeles\n",
    "2. **Robustez:** El ratio de inliers en  es alto (>70%), demostrando la robustez del método RANSAC\n",
    "3. **Limitaciones:** Las transformaciones combinadas presentan mayor error y el más bajo ratio de inliers\n",
    "4. **Validación exitosa:** El método está listo para aplicarse a imágenes reales\n",
    "\n",
    "**Próximo paso:** Aplicar el pipeline completo a las imágenes reales del comedor (Notebook 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDACIÓN SINTÉTICA COMPLETADA\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ Resultados guardados en:\")\n",
    "print(\"  - ../results/figures/\")\n",
    "print(\"  - ../results/measurements/\")\n",
    "print(\"\\nContinúe con el Notebook 03 para el pipeline completo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
