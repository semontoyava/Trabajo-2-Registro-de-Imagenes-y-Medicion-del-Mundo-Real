{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd1a46f",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Imágenes\n",
    "\n",
    "**Universidad Nacional de Colombia**  \n",
    "**Visión por Computador**  \n",
    "**Trabajo 2: Registro de Imágenes**\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Cargar y visualizar las imágenes del comedor\n",
    "2. Analizar características básicas (dimensiones, histogramas, etc.)\n",
    "3. Explorar diferentes detectores de características\n",
    "4. Comparar métodos de emparejamiento\n",
    "5. Identificar el mejor enfoque para el registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5537560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Importar módulos del proyecto\n",
    "from feature_detection import detect_sift_features, detect_orb_features, detect_akaze_features\n",
    "from feature_detection import compare_detectors, visualize_keypoints\n",
    "from matching import match_features, compute_match_statistics, visualize_matches\n",
    "from utils import load_images_from_directory\n",
    "\n",
    "# Configuración de matplotlib\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99972be9",
   "metadata": {},
   "source": [
    "## 1. Carga de Imágenes\n",
    "\n",
    "Cargamos las imágenes del comedor que vamos a registrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322fb43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de imágenes\n",
    "data_dir = Path('../data/original')\n",
    "\n",
    "# Cargar imágenes\n",
    "images = load_images_from_directory(str(data_dir))\n",
    "\n",
    "print(f\"\\nTotal de imágenes cargadas: {len(images)}\")\n",
    "print(\"\\nDetalles:\")\n",
    "for i, (name, img) in enumerate(images, 1):\n",
    "    print(f\"  {i}. {name}: {img.shape[1]}x{img.shape[0]} píxeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222331ee",
   "metadata": {},
   "source": [
    "## 2. Visualización de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar todas las imágenes\n",
    "n_images = len(images)\n",
    "cols = 2\n",
    "rows = (n_images + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "axes = axes.flatten() if n_images > 1 else [axes]\n",
    "\n",
    "for idx, (name, img) in enumerate(images):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[idx].imshow(img_rgb)\n",
    "    axes[idx].set_title(f'{name}\\n{img.shape[1]}x{img.shape[0]}', fontsize=12)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Ocultar ejes vacíos\n",
    "for idx in range(n_images, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/01_images_overview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f193d0e",
   "metadata": {},
   "source": [
    "## 3. Análisis de Histogramas\n",
    "\n",
    "Analizamos la distribución de intensidades en cada canal de color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e733926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(img, title):\n",
    "    \"\"\"Muestra el histograma RGB de una imagen\"\"\"\n",
    "    colors = ('b', 'g', 'r')\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    for i, color in enumerate(colors):\n",
    "        hist = cv2.calcHist([img], [i], None, [256], [0, 256])\n",
    "        plt.plot(hist, color=color, label=f'Canal {color.upper()}')\n",
    "    \n",
    "    plt.xlim([0, 256])\n",
    "    plt.xlabel('Intensidad de píxel')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar histogramas\n",
    "for name, img in images[:2]:  # Primeras 2 imágenes\n",
    "    plot_histogram(img, f'Histograma RGB - {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cea793",
   "metadata": {},
   "source": [
    "## 4. Detección de Características\n",
    "\n",
    "Comparamos diferentes detectores de características en las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f667742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar la primera imagen para análisis\n",
    "if len(images) > 0:\n",
    "    test_name, test_img = images[0]\n",
    "    \n",
    "    print(f\"\\nAnalizando: {test_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Comparar detectores\n",
    "    results = compare_detectors(test_img, detectors=['sift', 'orb', 'akaze'])\n",
    "    \n",
    "    # Visualizar resultados\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for idx, (detector_name, (kp, desc)) in enumerate(results.items()):\n",
    "        img_with_kp = visualize_keypoints(test_img, kp)\n",
    "        img_rgb = cv2.cvtColor(img_with_kp, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(img_rgb)\n",
    "        axes[idx].set_title(f'{detector_name.upper()}\\n{len(kp)} keypoints', fontsize=14)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/02_detector_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Resumen estadístico\n",
    "    print(\"\\nRESUMEN DE DETECTORES:\")\n",
    "    print(\"-\" * 60)\n",
    "    for detector_name, (kp, desc) in results.items():\n",
    "        if desc is not None:\n",
    "            print(f\"\\n{detector_name.upper()}:\")\n",
    "            print(f\"  - Keypoints detectados: {len(kp)}\")\n",
    "            print(f\"  - Dimensión descriptor: {desc.shape[1]}\")\n",
    "            print(f\"  - Tipo descriptor: {desc.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2650a",
   "metadata": {},
   "source": [
    "## 5. Emparejamiento de Características\n",
    "\n",
    "Si hay al menos 2 imágenes, probamos el emparejamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(images) >= 2:\n",
    "    # Tomar dos imágenes\n",
    "    name1, img1 = images[0]\n",
    "    name2, img2 = images[1]\n",
    "    \n",
    "    print(f\"\\nEmparejando: {name1} <-> {name2}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Detectar características con SIFT\n",
    "    kp1, desc1 = detect_sift_features(img1)\n",
    "    kp2, desc2 = detect_sift_features(img2)\n",
    "    \n",
    "    # Probar diferentes métodos de emparejamiento\n",
    "    methods = ['flann', 'bf']\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\n{method.upper()}:\")\n",
    "        matches = match_features(desc1, desc2, method=method, ratio_test=0.75)\n",
    "        \n",
    "        # Estadísticas\n",
    "        stats = compute_match_statistics(matches)\n",
    "        print(f\"  - Matches: {stats['num_matches']}\")\n",
    "        print(f\"  - Distancia promedio: {stats['mean_distance']:.2f}\")\n",
    "        print(f\"  - Distancia std: {stats['std_distance']:.2f}\")\n",
    "        \n",
    "        # Visualizar\n",
    "        img_matches = visualize_matches(img1, kp1, img2, kp2, matches, max_matches=50)\n",
    "        img_matches_rgb = cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.imshow(img_matches_rgb)\n",
    "        plt.title(f'Matches - {method.upper()}: {len(matches)} matches', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'../results/figures/03_matches_{method}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"⚠ Se necesitan al menos 2 imágenes para emparejar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb8331",
   "metadata": {},
   "source": [
    "## 6. Conclusiones del Análisis Exploratorio\n",
    "\n",
    "**Resumen:**\n",
    "\n",
    "1. **Imágenes cargadas:** Se han cargado las imágenes del comedor exitosamente\n",
    "2. **Detectores:** \n",
    "   - SIFT: Mejor para imágenes de alta calidad, más keypoints robustos\n",
    "   - ORB: Más rápido, bueno para aplicaciones en tiempo real\n",
    "   - AKAZE: Balance entre velocidad y precisión\n",
    "3. **Emparejamiento:**\n",
    "   - FLANN es más rápido para conjuntos grandes\n",
    "   - BFMatcher es más preciso pero más lento\n",
    "4. **Recomendación:** Usar SIFT con FLANN para el registro final\n",
    "\n",
    "**Próximos pasos:**\n",
    "- Validar con imágenes sintéticas (Notebook 02)\n",
    "- Implementar pipeline completo de registro (Notebook 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d975059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANÁLISIS EXPLORATORIO COMPLETADO\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ Resultados guardados en: ../results/figures/\")\n",
    "print(\"\\nContinúe con el Notebook 02 para validación sintética.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
