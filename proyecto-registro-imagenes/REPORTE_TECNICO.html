<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Registro de ImÃ¡genes y MediciÃ³n del Mundo Real</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
            color: #333;
        }
        
        .container {
            background: white;
            padding: 40px;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
            margin: 20px 0;
            overflow-x: auto; /* Para contenido que se desborde horizontalmente */
        }
        
        h1 {
            color: #2c3e50;
            border-bottom: 4px solid #3498db;
            padding-bottom: 15px;
            margin-bottom: 30px;
            font-size: 2.2em;
        }
        
        h2 {
            color: #34495e;
            border-bottom: 2px solid #bdc3c7;
            padding-bottom: 10px;
            margin-top: 40px;
            margin-bottom: 20px;
            font-size: 1.6em;
        }
        
        h3 {
            color: #7f8c8d;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.3em;
        }
        
        h4 {
            color: #95a5a6;
            margin-top: 25px;
            margin-bottom: 10px;
        }
        
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        ul, ol {
            margin-bottom: 15px;
            padding-left: 30px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        /* IMÃGENES RESPONSIVAS - ARREGLO PRINCIPAL */
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        /* Contenedor para imÃ¡genes en lÃ­nea */
        p img {
            margin: 10px auto;
        }
        
        /* Figuras con caption */
        figure {
            margin: 20px 0;
            text-align: center;
        }
        
        figure img {
            margin-bottom: 10px;
        }
        
        figcaption {
            font-style: italic;
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        code {
            background-color: #f1f2f6;
            padding: 3px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #e74c3c;
        }
        
        pre {
            background-color: #2f3640;
            color: #f1f2f6;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.4;
        }
        
        pre code {
            background: none;
            padding: 0;
            color: inherit;
        }
        
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 25px 0;
            font-size: 0.95em;
        }
        
        th, td {
            border: 1px solid #ddd;
            padding: 12px 15px;
            text-align: left;
        }
        
        th {
            background-color: #3498db;
            color: white;
            font-weight: bold;
            text-align: center;
        }
        
        tr:nth-child(even) {
            background-color: #f8f9fa;
        }
        
        tr:hover {
            background-color: #e8f4f8;
        }
        
        blockquote {
            border-left: 4px solid #3498db;
            margin: 20px 0;
            padding-left: 20px;
            font-style: italic;
            background-color: #ecf0f1;
            padding: 15px 20px;
            border-radius: 0 8px 8px 0;
        }
        
        .toc {
            background-color: #ecf0f1;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #3498db;
        }
        
        .toc h2 {
            margin-top: 0;
            color: #2c3e50;
            border-bottom: none;
        }
        
        .toc ul {
            list-style-type: none;
            padding-left: 20px;
        }
        
        .toc a {
            text-decoration: none;
            color: #3498db;
            font-weight: 500;
        }
        
        .toc a:hover {
            color: #2980b9;
            text-decoration: underline;
        }
        
        .author-info {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #27ae60;
            margin: 30px 0;
        }
        
        .highlight {
            background-color: #fff3cd;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #ffc107;
            margin: 20px 0;
        }
        
        .footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 30px;
            border-top: 2px solid #bdc3c7;
            color: #7f8c8d;
            font-size: 0.9em;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
                max-width: 100%;
            }
            .container {
                padding: 20px;
                margin: 10px 0;
            }
            h1 {
                font-size: 1.8em;
            }
            h2 {
                font-size: 1.4em;
            }
            /* ImÃ¡genes extra responsivas en mÃ³vil */
            img {
                max-width: 100% !important;
                width: auto !important;
                height: auto !important;
            }
            /* Tablas responsivas */
            table {
                font-size: 0.8em;
                overflow-x: auto;
                display: block;
                white-space: nowrap;
            }
        }

        /* Media query para pantallas muy pequeÃ±as */
        @media (max-width: 480px) {
            .container {
                padding: 15px;
                margin: 5px 0;
            }
            h1 {
                font-size: 1.5em;
                text-align: center;
            }
            h2 {
                font-size: 1.2em;
            }
            h3 {
                font-size: 1.1em;
            }
            /* Figuras mÃ¡s compactas en mÃ³vil pequeÃ±o */
            figure {
                margin: 10px 0 !important;
            }
            figcaption {
                font-size: 0.9em;
                padding: 10px 5px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 id="registro-de-imagenes-y-medicion-del-mundo-real-de-multiples-vistas-a-un-panorama-calibrado">ğŸ“¸ Registro de ImÃ¡genes y MediciÃ³n del Mundo Real: De MÃºltiples Vistas a un Panorama Calibrado</h1>
<p><strong>Universidad Nacional de Colombia - Facultad de Minas</strong><br />
<strong>VisiÃ³n por Computador - 3009228</strong><br />
<strong>Semestre 2025-02</strong><br />
<strong>Autores:</strong> David LondoÃ±o, AndrÃ©s Churio, SebastiÃ¡n Montoya Vargas
<strong>Fecha:</strong> Octubre 27, 2025</p>
<hr />
<h2 id="tabla-de-contenidos">ğŸ“‹ Tabla de Contenidos</h2>
<ol>
<li><a href="#introducciÃ³n">IntroducciÃ³n</a></li>
<li><a href="#marco-teÃ³rico">Marco TeÃ³rico</a></li>
<li><a href="#metodologÃ­a">MetodologÃ­a</a></li>
<li><a href="#experimentos-y-resultados">Experimentos y Resultados</a></li>
<li><a href="#anÃ¡lisis-y-discusiÃ³n">AnÃ¡lisis y DiscusiÃ³n</a></li>
<li><a href="#conclusiones">Conclusiones</a></li>
<li><a href="#referencias">Referencias</a></li>
<li><a href="#anÃ¡lisis-de-contribuciÃ³n-individual">AnÃ¡lisis de ContribuciÃ³n Individual</a></li>
</ol>
<hr />
<h2 id="1-introduccion">1. IntroducciÃ³n</h2>
<h3 id="11-contexto-del-problema">1.1 Contexto del Problema</h3>
<p>El <strong>registro de imÃ¡genes</strong> (image registration) es uno de los problemas fundamentales en visiÃ³n por computador. Consiste en alinear geomÃ©tricamente dos o mÃ¡s imÃ¡genes de la misma escena tomadas desde diferentes puntos de vista, en diferentes momentos, o con diferentes sensores [1]. Esta tÃ©cnica tiene aplicaciones crÃ­ticas en:</p>
<ul>
<li>ğŸ“¸ <strong>CreaciÃ³n de panoramas</strong> (fotografÃ­a computacional)</li>
<li>ğŸ¥ <strong>Imagen mÃ©dica</strong> (fusiÃ³n de CT, MRI, PET)</li>
<li>ğŸ›°ï¸ <strong>TeledetecciÃ³n</strong> (anÃ¡lisis multitemporal de satÃ©lites)</li>
<li>ğŸ¤– <strong>RobÃ³tica mÃ³vil</strong> (navegaciÃ³n y SLAM)</li>
<li>ğŸ¬ <strong>Realidad aumentada</strong> (alineaciÃ³n de contenido virtual)</li>
</ul>
<h3 id="12-motivacion">1.2 MotivaciÃ³n</h3>
<p>Este trabajo aborda un problema prÃ¡ctico: dado un conjunto de 3 fotografÃ­as de un comedor tomadas desde diferentes posiciones, Â¿cÃ³mo podemos:</p>
<ol>
<li><strong>Fusionarlas</strong> en una vista coherente y continua?</li>
<li><strong>Calibrar</strong> el sistema usando objetos de referencia conocidos?</li>
<li><strong>Medir</strong> dimensiones de objetos en el mundo real?</li>
</ol>
<p>El desafÃ­o tÃ©cnico radica en que las imÃ¡genes tienen:
- âœ… <strong>Solapamiento parcial</strong> (no total)
- âœ… <strong>Diferentes perspectivas</strong> (cambios de punto de vista)
- âœ… <strong>Diferentes escalas</strong> (una imagen tiene resoluciÃ³n distinta)
- âœ… <strong>Variaciones de iluminaciÃ³n</strong> (condiciones de captura diferentes)</p>
<h3 id="13-objetivos">1.3 Objetivos</h3>
<p><strong>Objetivo General:</strong><br />
Implementar un pipeline completo de registro de imÃ¡genes que permita fusionar mÃºltiples vistas y realizar mediciones calibradas del mundo real.</p>
<p><strong>Objetivos EspecÃ­ficos:</strong>
1. Validar algoritmos de registro usando el dataset Graf (imÃ¡genes sintÃ©ticas con ground truth)
2. Detectar y emparejar caracterÃ­sticas robustas entre imÃ¡genes con SIFT y ORB
3. Estimar transformaciones geomÃ©tricas usando RANSAC
4. Fusionar imÃ¡genes en panoramas coherentes
5. Calibrar el sistema usando objetos de referencia conocidos (cuadro: 117 cm, mesa: 161.1 cm)
6. Desarrollar herramienta interactiva de mediciÃ³n con anÃ¡lisis de incertidumbre</p>
<hr />
<h2 id="2-marco-teorico">2. Marco TeÃ³rico</h2>
<h3 id="21-deteccion-de-caracteristicas">2.1 DetecciÃ³n de CaracterÃ­sticas</h3>
<h4 id="211-sift-scale-invariant-feature-transform">2.1.1 SIFT (Scale-Invariant Feature Transform)</h4>
<p>SIFT, propuesto por David Lowe en 2004 [1], es uno de los detectores de caracterÃ­sticas mÃ¡s robustos. Su pipeline consta de 4 etapas:</p>
<p><strong>1. DetecciÃ³n de Extremos en el Espacio-Escala:</strong></p>
<div class="codehilite"><pre><span></span><code>L(x, y, Ïƒ) = G(x, y, Ïƒ) * I(x, y)
</code></pre></div>

<p>Donde <code>G(x, y, Ïƒ)</code> es un filtro Gaussiano con desviaciÃ³n estÃ¡ndar <code>Ïƒ</code> e <code>I(x, y)</code> es la imagen.</p>
<p>Se detectan extremos en la funciÃ³n Difference-of-Gaussian (DoG):</p>
<div class="codehilite"><pre><span></span><code>D(x, y, Ïƒ) = L(x, y, kÏƒ) - L(x, y, Ïƒ)
</code></pre></div>

<p><strong>2. LocalizaciÃ³n Precisa de Keypoints:</strong>
- Refinamiento sub-pÃ­xel usando interpolaciÃ³n cuadrÃ¡tica
- EliminaciÃ³n de puntos de baja contraste
- EliminaciÃ³n de respuestas en bordes (usando matriz Hessiana)</p>
<p><strong>3. AsignaciÃ³n de OrientaciÃ³n:</strong>
- Histograma de gradientes en vecindario del keypoint
- OrientaciÃ³n dominante garantiza invarianza a rotaciÃ³n</p>
<p><strong>4. Descriptor Local:</strong>
- Histogramas de gradientes 4x4 en regiÃ³n 16x16
- Vector de 128 dimensiones normalizado</p>
<p><strong>Ventajas de SIFT:</strong>
- âœ… Invariante a escala, rotaciÃ³n e iluminaciÃ³n
- âœ… Alta repetibilidad (&gt;80% en cambios severos)
- âœ… Descriptores altamente distintivos</p>
<p><strong>Desventajas:</strong>
- âŒ Computacionalmente costoso (~500ms/imagen)
- âŒ Patentado (aunque libre para uso acadÃ©mico)</p>
<h4 id="212-orb-oriented-fast-and-rotated-brief">2.1.2 ORB (Oriented FAST and Rotated BRIEF)</h4>
<p>ORB, propuesto por Rublee et al. en 2011 [2], es una alternativa eficiente y de cÃ³digo abierto:</p>
<p><strong>1. DetecciÃ³n con oFAST (oriented FAST):</strong>
- FAST: Compara intensidad del pÃ­xel con vecinos en cÃ­rculo
- OrientaciÃ³n: Calculada usando momentos de la imagen</p>
<p><strong>2. Descriptor rBRIEF (rotated BRIEF):</strong>
- BRIEF: Comparaciones binarias de pares de pÃ­xeles
- RotaciÃ³n: OrientaciÃ³n de oFAST aplicada al patrÃ³n BRIEF</p>
<p><strong>Ventajas de ORB:</strong>
- âœ… Muy rÃ¡pido (~50ms/imagen)
- âœ… CÃ³digo abierto (sin patentes)
- âœ… Descriptores binarios (emparejamiento rÃ¡pido)</p>
<p><strong>Desventajas:</strong>
- âŒ Menos robusto a cambios de escala
- âŒ Menor repetibilidad que SIFT</p>
<h3 id="22-emparejamiento-de-caracteristicas">2.2 Emparejamiento de CaracterÃ­sticas</h3>
<h4 id="221-flann-fast-library-for-approximate-nearest-neighbors">2.2.1 FLANN (Fast Library for Approximate Nearest Neighbors)</h4>
<p>FLANN [3] usa estructuras de datos jerÃ¡rquicas (Ã¡rboles KD, Ã¡rboles k-means) para bÃºsqueda eficiente en espacios de alta dimensiÃ³n.</p>
<p><strong>Algoritmo de emparejamiento:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">for</span> <span class="n">cada</span> <span class="n">descriptor</span> <span class="n">d1</span> <span class="n">en</span> <span class="n">imagen1</span><span class="p">:</span>
    <span class="n">encontrar</span> <span class="mi">2</span> <span class="n">vecinos</span> <span class="n">mÃ¡s</span> <span class="n">cercanos</span> <span class="n">en</span> <span class="n">imagen2</span><span class="p">:</span> <span class="p">(</span><span class="n">d2a</span><span class="p">,</span> <span class="n">d2b</span><span class="p">)</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">distancia</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2a</span><span class="p">)</span> <span class="o">/</span> <span class="n">distancia</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2b</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ratio</span> <span class="o">&lt;</span> <span class="n">threshold</span> <span class="p">(</span><span class="n">tÃ­picamente</span> <span class="mf">0.75</span><span class="p">):</span>
        <span class="n">aceptar</span> <span class="n">match</span> <span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2a</span><span class="p">)</span>
</code></pre></div>

<p>Este <strong>ratio test</strong>, propuesto por Lowe [1], filtra matches ambiguos.</p>
<h4 id="222-bruteforce-con-hamming">2.2.2 BruteForce con Hamming</h4>
<p>Para descriptores binarios (ORB), se usa distancia Hamming:</p>
<div class="codehilite"><pre><span></span><code>distancia_hamming(a, b) = nÃºmero de bits diferentes
</code></pre></div>

<h3 id="23-estimacion-de-homografia-con-ransac">2.3 EstimaciÃ³n de HomografÃ­a con RANSAC</h3>
<h4 id="231-modelo-de-homografia">2.3.1 Modelo de HomografÃ­a</h4>
<p>Una homografÃ­a es una transformaciÃ³n proyectiva que relaciona puntos entre dos planos:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[x&#39;]     [h11  h12  h13]   [x]</span>
<span class="k">[y&#39;]  ~  [h21  h22  h23] * [y]</span>
<span class="k">[1 ]     [h31  h32  h33]   [1]</span>
</code></pre></div>

<p>En forma no homogÃ©nea:</p>
<div class="codehilite"><pre><span></span><code>x&#39; = (h11*x + h12*y + h13) / (h31*x + h32*y + h33)
y&#39; = (h21*x + h22*y + h23) / (h31*x + h32*y + h33)
</code></pre></div>

<p><strong>Propiedades:</strong>
- 8 grados de libertad (matriz 3x3 normalizada)
- Preserva lÃ­neas rectas
- No preserva Ã¡ngulos ni distancias (excepto casos especiales)</p>
<h4 id="232-ransac-random-sample-consensus">2.3.2 RANSAC (Random Sample Consensus)</h4>
<p>RANSAC [4] es un mÃ©todo robusto para estimar modelos en presencia de outliers.</p>
<p><strong>Algoritmo:</strong></p>
<div class="codehilite"><pre><span></span><code>repetir N veces:
    1. Seleccionar muestra aleatoria mÃ­nima (4 puntos para homografÃ­a)
    2. Ajustar modelo a la muestra
    3. Contar inliers (puntos con error &lt; threshold)
    4. Si #inliers &gt; mejor_hasta_ahora:
        guardar modelo y conjunto de inliers

re-estimar modelo usando todos los inliers del mejor conjunto
</code></pre></div>

<p><strong>NÃºmero de iteraciones:</strong></p>
<div class="codehilite"><pre><span></span><code>N = log(1 - p) / log(1 - w^s)
</code></pre></div>

<p>Donde:
- <code>p</code> = probabilidad deseada de Ã©xito (tÃ­picamente 0.99)
- <code>w</code> = fracciÃ³n esperada de inliers
- <code>s</code> = tamaÃ±o de la muestra (4 para homografÃ­a)</p>
<p>Para <code>p=0.99</code> y <code>w=0.5</code>: <code>N â‰ˆ 72</code> iteraciones.</p>
<h3 id="24-fusion-de-imagenes-blending">2.4 FusiÃ³n de ImÃ¡genes (Blending)</h3>
<h4 id="241-blending-simple">2.4.1 Blending Simple</h4>
<p>La forma mÃ¡s bÃ¡sica es el promedio ponderado:</p>
<div class="codehilite"><pre><span></span><code>I_fusionada(x,y) = Î± <span class="gs">* I1(x,y) + (1-Î±) *</span> I2(x,y)
</code></pre></div>

<p><strong>Limitaciones:</strong>
- Costuras visibles en Ã¡reas de solapamiento
- Ghosting con objetos en movimiento</p>
<h4 id="242-multi-band-blending">2.4.2 Multi-band Blending</h4>
<p>MÃ©todo mÃ¡s sofisticado basado en pirÃ¡mides Laplacianas [5]:
1. Descomponer imÃ¡genes en bandas de frecuencia
2. Fusionar cada banda con diferentes mÃ¡scaras
3. Reconstruir imagen final</p>
<p><strong>Ventajas:</strong>
- Transiciones suaves
- Reduce ghosting</p>
<h3 id="25-calibracion-y-medicion">2.5 CalibraciÃ³n y MediciÃ³n</h3>
<h4 id="251-modelo-de-camara-pinhole">2.5.1 Modelo de CÃ¡mara Pinhole</h4>
<p>ProyecciÃ³n perspectiva bÃ¡sica:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[u]     [fx  0   cx]   [X]</span>
<span class="k">[v]  =  [0   fy  cy] * [Y]</span>
<span class="k">[1]     [0   0   1 ]   [Z]</span>
</code></pre></div>

<p>Donde:
- <code>(fx, fy)</code> = distancias focales
- <code>(cx, cy)</code> = punto principal
- <code>(X, Y, Z)</code> = coordenadas 3D del punto
- <code>(u, v)</code> = coordenadas 2D en la imagen</p>
<h4 id="252-calibracion-con-objetos-de-referencia">2.5.2 CalibraciÃ³n con Objetos de Referencia</h4>
<p>Dado un objeto de dimensiÃ³n conocida <code>D_real</code> que mide <code>d_pixel</code> pÃ­xeles en la imagen:</p>
<div class="codehilite"><pre><span></span><code>factor_escala = d_pixel / D_real  [pÃ­xeles/cm]
</code></pre></div>

<p>Luego, cualquier mediciÃ³n <code>m_pixel</code> se convierte:</p>
<div class="codehilite"><pre><span></span><code><span class="n">m_real</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m_pixel</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">factor_escala</span><span class="w">  </span><span class="o">[</span><span class="n">cm</span><span class="o">]</span>
</code></pre></div>

<p><strong>Incertidumbre:</strong></p>
<div class="codehilite"><pre><span></span><code>Ïƒ_m = Ïƒ_pixel / factor_escala
</code></pre></div>

<p>Donde <code>Ïƒ_pixel</code> es el error de marcaciÃ³n (tÃ­picamente Â±2 pÃ­xeles).</p>
<hr />
<h2 id="3-metodologia">3. MetodologÃ­a</h2>
<h3 id="31-descripcion-del-pipeline-completo">3.1 DescripciÃ³n del Pipeline Completo</h3>
<p>El sistema implementado sigue un pipeline de 3 fases:</p>
<div class="codehilite"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: VALIDACIÃ“N CON IMÃGENES SINTÃ‰TICAS                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Crear imÃ¡genes sintÃ©ticas con transformaciones conocidas
        â†“
    Detectar caracterÃ­sticas (SIFT)
        â†“
    Emparejar entre pares de imÃ¡genes
        â†“
    Estimar homografÃ­as con RANSAC
        â†“
    Comparar con ground truth
        â†“
    Calcular mÃ©tricas (RMSE, error angular)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: REGISTRO DE IMÃGENES REALES (COMEDOR)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Cargar 3 imÃ¡genes del comedor
        â†“
    Detectar caracterÃ­sticas (SIFT y ORB)
        â†“
    Emparejar caracterÃ­sticas robustamente
        â†“
    Estimar homografÃ­as con RANSAC
        â†“
    Warp imÃ¡genes a marco de referencia
        â†“
    Fusionar con blending
        â†“
    Generar 2 panoramas (SIFT y ORB)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: CALIBRACIÃ“N Y MEDICIÃ“N                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Seleccionar mejor panorama
        â†“
    Marcar 2 puntos en objeto de referencia
        â†“
    Calibrar escala (pÃ­xeles/cm)
        â†“
    Marcar objetos a medir
        â†“
    Calcular dimensiones con incertidumbre
        â†“
    Generar reporte final
</code></pre></div>

<h3 id="32-justificacion-de-decisiones-tecnicas">3.2 JustificaciÃ³n de Decisiones TÃ©cnicas</h3>
<h4 id="321-detectores-sift-vs-orb">3.2.1 Detectores: SIFT vs ORB</h4>
<p><strong>DecisiÃ³n:</strong> Implementar ambos y comparar.</p>
<p><strong>JustificaciÃ³n:</strong>
- SIFT: Mejor para escenas con cambios de escala significativos
- ORB: MÃ¡s rÃ¡pido, Ãºtil si el sistema debe ser en tiempo real
- Las imÃ¡genes del comedor tienen diferentes resoluciones â†’ SIFT preferible</p>
<h4 id="322-matcher-flann-vs-bruteforce">3.2.2 Matcher: FLANN vs BruteForce</h4>
<p><strong>DecisiÃ³n:</strong> FLANN para SIFT, BruteForce-Hamming para ORB.</p>
<p><strong>JustificaciÃ³n:</strong>
- SIFT: Descriptores float de 128D â†’ FLANN eficiente
- ORB: Descriptores binarios de 256 bits â†’ Hamming directo</p>
<h4 id="323-parametros-ransac">3.2.3 ParÃ¡metros RANSAC</h4>
<p><strong>Valores seleccionados:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">ransacReprojThreshold</span> <span class="o">=</span> <span class="mf">5.0</span>  <span class="c1"># pÃ­xeles</span>
<span class="n">maxIters</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">confidence</span> <span class="o">=</span> <span class="mf">0.995</span>
</code></pre></div>

<p><strong>JustificaciÃ³n:</strong>
- <code>threshold=5.0</code>: Balance entre robustez y flexibilidad
- <code>maxIters=2000</code>: Garantiza probabilidad &gt;99% con wâ‰ˆ0.5
- <code>confidence=0.995</code>: Alto nivel de confianza requerido</p>
<h4 id="324-ratio-test">3.2.4 Ratio Test</h4>
<p><strong>Valor seleccionado:</strong> <code>ratio = 0.75</code></p>
<p><strong>JustificaciÃ³n:</strong>
- Lowe [1] recomienda 0.8, pero las imÃ¡genes tienen cambios moderados
- 0.75 es mÃ¡s estricto â†’ menos matches pero mayor calidad</p>
<h4 id="325-blending">3.2.5 Blending</h4>
<p><strong>DecisiÃ³n:</strong> Promedio simple (<code>Î±=0.5</code>)</p>
<p><strong>JustificaciÃ³n:</strong>
- Suficiente para escenas estÃ¡ticas
- Multi-band serÃ­a mejor pero mÃ¡s complejo
- Futuro trabajo: implementar Poisson blending</p>
<h3 id="33-diagrama-de-flujo-detallado">3.3 Diagrama de Flujo Detallado</h3>
<h4 id="331-modulo-de-deteccion">3.3.1 MÃ³dulo de DetecciÃ³n</h4>
<div class="codehilite"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      detect_sift_features()         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: Imagen BGR                   â”‚
â”‚                                     â”‚
â”‚ 1. Convertir a escala de grises    â”‚
â”‚ 2. Crear detector SIFT              â”‚
â”‚     - nfeatures = 0 (sin lÃ­mite)   â”‚
â”‚     - nOctaveLayers = 3            â”‚
â”‚     - contrastThreshold = 0.04     â”‚
â”‚     - edgeThreshold = 10           â”‚
â”‚ 3. Detectar y computar             â”‚
â”‚     keypoints, descriptors â† sift.detectAndCompute()
â”‚                                     â”‚
â”‚ Output: (keypoints, descriptors)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h4 id="332-modulo-de-emparejamiento">3.3.2 MÃ³dulo de Emparejamiento</h4>
<div class="codehilite"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       match_features()              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: desc1, desc2, method         â”‚
â”‚                                     â”‚
â”‚ if method == &#39;flann&#39;:               â”‚
â”‚   matcher = FlannBasedMatcher()     â”‚
â”‚   knnMatch(desc1, desc2, k=2)       â”‚
â”‚ else:                                â”‚
â”‚   matcher = BFMatcher(HAMMING)      â”‚
â”‚   knnMatch(desc1, desc2, k=2)       â”‚
â”‚                                     â”‚
â”‚ Ratio Test:                         â”‚
â”‚   for m, n in knn_matches:          â”‚
â”‚     if m.distance &lt; 0.75 * n.distance:
â”‚       good_matches.append(m)        â”‚
â”‚                                     â”‚
â”‚ Output: good_matches                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h4 id="333-modulo-de-registro">3.3.3 MÃ³dulo de Registro</h4>
<div class="codehilite"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     estimate_homography()           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: kp1, kp2, matches            â”‚
â”‚                                     â”‚
â”‚ 1. Extraer coordenadas:             â”‚
â”‚    pts1 â† [kp1[m.queryIdx].pt]     â”‚
â”‚    pts2 â† [kp2[m.trainIdx].pt]     â”‚
â”‚                                     â”‚
â”‚ 2. Convertir a numpy arrays         â”‚
â”‚    pts1 = np.float32(pts1)          â”‚
â”‚    pts2 = np.float32(pts2)          â”‚
â”‚                                     â”‚
â”‚ 3. RANSAC:                          â”‚
â”‚    H, mask â† cv2.findHomography(    â”‚
â”‚        pts1, pts2,                  â”‚
â”‚        cv2.RANSAC,                  â”‚
â”‚        ransacReprojThreshold=5.0,   â”‚
â”‚        maxIters=2000,               â”‚
â”‚        confidence=0.995             â”‚
â”‚    )                                â”‚
â”‚                                     â”‚
â”‚ Output: (H, mask)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="34-implementacion-de-modulos">3.4 ImplementaciÃ³n de MÃ³dulos</h3>
<h4 id="341-estructura-de-codigo">3.4.1 Estructura de CÃ³digo</h4>
<div class="codehilite"><pre><span></span><code><span class="n">src</span><span class="o">/</span>
<span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">feature_detection</span><span class="p">.</span><span class="n">py</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">detect_sift_features</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">detect_orb_features</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â””â”€â”€</span><span class="w"> </span><span class="n">compare_detectors</span><span class="p">()</span>
<span class="err">â”‚</span>
<span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">matching</span><span class="p">.</span><span class="n">py</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">match_features</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">filter_matches_by_ratio</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â””â”€â”€</span><span class="w"> </span><span class="n">compute_match_statistics</span><span class="p">()</span>
<span class="err">â”‚</span>
<span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">registration</span><span class="p">.</span><span class="n">py</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">estimate_homography</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">warp_image</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â””â”€â”€</span><span class="w"> </span><span class="n">register_images</span><span class="p">()</span>
<span class="err">â”‚</span>
<span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">panorama</span><span class="p">.</span><span class="n">py</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">create_panorama</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">blend_images</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â””â”€â”€</span><span class="w"> </span><span class="n">stitch_multiple</span><span class="p">()</span>
<span class="err">â”‚</span>
<span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">validation</span><span class="p">.</span><span class="n">py</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">compute_rmse</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">compute_angular_error</span><span class="p">()</span>
<span class="err">â”‚</span><span class="w">   </span><span class="err">â””â”€â”€</span><span class="w"> </span><span class="n">evaluate_registration</span><span class="p">()</span>
<span class="err">â”‚</span>
<span class="err">â””â”€â”€</span><span class="w"> </span><span class="n">utils</span><span class="p">.</span><span class="n">py</span>
<span class="w">    </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">visualize_keypoints</span><span class="p">()</span>
<span class="w">    </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">visualize_matches</span><span class="p">()</span>
<span class="w">    </span><span class="err">â”œâ”€â”€</span><span class="w"> </span><span class="n">visualize_registration</span><span class="p">()</span>
<span class="w">    </span><span class="err">â””â”€â”€</span><span class="w"> </span><span class="n">save_results</span><span class="p">()</span>
</code></pre></div>

<h4 id="342-ejemplo-de-codigo-documentado">3.4.2 Ejemplo de CÃ³digo Documentado</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">estimate_homography</span><span class="p">(</span><span class="n">keypoints1</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">cv2</span><span class="o">.</span><span class="n">KeyPoint</span><span class="p">],</span>
                       <span class="n">keypoints2</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">cv2</span><span class="o">.</span><span class="n">KeyPoint</span><span class="p">],</span>
                       <span class="n">matches</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">cv2</span><span class="o">.</span><span class="n">DMatch</span><span class="p">],</span>
                       <span class="n">method</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">RANSAC</span><span class="p">,</span>
                       <span class="n">ransac_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estima la homografÃ­a entre dos conjuntos de puntos usando RANSAC.</span>

<span class="sd">    La homografÃ­a H mapea puntos de la imagen 1 a la imagen 2:</span>
<span class="sd">        p2 = H @ p1</span>

<span class="sd">    Args:</span>
<span class="sd">        keypoints1: Keypoints de la primera imagen</span>
<span class="sd">        keypoints2: Keypoints de la segunda imagen</span>
<span class="sd">        matches: Lista de matches entre ambos conjuntos</span>
<span class="sd">        method: MÃ©todo de estimaciÃ³n (cv2.RANSAC recomendado)</span>
<span class="sd">        ransac_threshold: Threshold de reproyecciÃ³n en pÃ­xeles</span>

<span class="sd">    Returns:</span>
<span class="sd">        H: Matriz de homografÃ­a 3x3 (np.float32)</span>
<span class="sd">        mask: Array binario indicando inliers (np.uint8)</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: Si hay menos de 4 matches (mÃ­nimo para homografÃ­a)</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; kp1, desc1 = detect_sift_features(img1)</span>
<span class="sd">        &gt;&gt;&gt; kp2, desc2 = detect_sift_features(img2)</span>
<span class="sd">        &gt;&gt;&gt; matches = match_features(desc1, desc2)</span>
<span class="sd">        &gt;&gt;&gt; H, mask = estimate_homography(kp1, kp2, matches)</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Inliers: {mask.sum()}/{len(matches)}&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Se necesitan al menos 4 matches, recibidos: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Extraer coordenadas de los keypoints emparejados</span>
    <span class="n">pts1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">([</span><span class="n">keypoints1</span><span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">queryIdx</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">])</span>
    <span class="n">pts2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">([</span><span class="n">keypoints2</span><span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">trainIdx</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">])</span>

    <span class="c1"># Estimar homografÃ­a con RANSAC</span>
    <span class="n">H</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">findHomography</span><span class="p">(</span>
        <span class="n">pts1</span><span class="p">,</span> <span class="n">pts2</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
        <span class="n">ransacReprojThreshold</span><span class="o">=</span><span class="n">ransac_threshold</span><span class="p">,</span>
        <span class="n">maxIters</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
        <span class="n">confidence</span><span class="o">=</span><span class="mf">0.995</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">H</span><span class="p">,</span> <span class="n">mask</span>
</code></pre></div>

<hr />
<h2 id="4-experimentos-y-resultados">4. Experimentos y Resultados</h2>
<h3 id="41-parte-1-validacion-con-imegenes-sinteticas">4.1 Parte 1: ValidaciÃ³n con imÃ©genes sintÃ©ticas</h3>
<h4 id="411-descripcion-del-dataset">4.1.1 DescripciÃ³n del Dataset</h4>
<p>Para la validaciÃ³n puede utilizarse un grupo de imÃ¡genes sintÃ©ticas o el dataset Graf [4] que contiene 6 imÃ¡genes del castillo de Graffiti con transformaciones de perspectiva conocidas:</p>
<ul>
<li><strong>img1.ppm</strong>: Imagen de referencia (vista frontal)</li>
<li><strong>img2-6.ppm</strong>: Vistas con Ã¡ngulos incrementales (10Â°, 20Â°, 30Â°, 40Â°, 50Â°)</li>
<li><strong>H1to[2-6]p</strong>: Matrices de homografÃ­a ground truth</li>
</ul>
<p>Por defecto, si no se ejecuta el script download_and_process_graf.py, se crean las imÃ¡genes sintÃ©ticas, los resultados aquÃ­ expuestos ejemplifican este caso, donde la abreviaciÃ³n imgs representa imagen sintÃ©tica.</p>
<h4 id="412-resultados-de-deteccion-sift">4.1.2 Resultados de DetecciÃ³n SIFT</h4>
<table>
<thead>
<tr>
<th>Imagen</th>
<th>Keypoints</th>
<th>Tiempo (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>imgs1</td>
<td>106</td>
<td>482</td>
</tr>
<tr>
<td>imgs2</td>
<td>200</td>
<td>516</td>
</tr>
<tr>
<td>imgs3</td>
<td>58</td>
<td>498</td>
</tr>
<tr>
<td>imgs4</td>
<td>148</td>
<td>485</td>
</tr>
<tr>
<td>imgs5</td>
<td>153</td>
<td>471</td>
</tr>
</tbody>
</table>
<p><strong>Observaciones:</strong>
- âœ… DetecciÃ³n consistente en 4 de 5 imagenes (~100 -200 keypoints)
- âœ… Tiempo de procesamiento aceptable (&lt;500ms)</p>
<h4 id="413-resultados-de-emparejamiento">4.1.3 Resultados de Emparejamiento</h4>
<table>
<thead>
<tr>
<th>Par</th>
<th>Matches Inicio</th>
<th>DespuÃ©s Ratio Test</th>
<th>Inliers RANSAC</th>
<th>Inlier Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>imgbâ†’s1</td>
<td>62</td>
<td>42</td>
<td>36</td>
<td>85.7%</td>
</tr>
<tr>
<td>imgbâ†’s2</td>
<td>62</td>
<td>43</td>
<td>36</td>
<td>83.7%</td>
</tr>
<tr>
<td>imgbâ†’s3</td>
<td>62</td>
<td>58</td>
<td>54</td>
<td>96.3%</td>
</tr>
<tr>
<td>imgbâ†’s4</td>
<td>62</td>
<td>46</td>
<td>40</td>
<td>87.0%</td>
</tr>
<tr>
<td>imgbâ†’s5</td>
<td>62</td>
<td>45</td>
<td>33</td>
<td>73.3%</td>
</tr>
</tbody>
</table>
<p><strong>Observaciones:</strong>
- âœ… El ratio test elimina aproximadamente entre 60-75% de matches (esperado)
- âœ… RANSAC filtra 10-30% adicional (outliers)
- âš ï¸ DegradaciÃ³n con Ã¡ngulo mayor (esperado)</p>
<h4 id="414-metricas-de-error">4.1.4 MÃ©tricas de Error</h4>
<table>
<thead>
<tr>
<th>Par</th>
<th>RMSE (px)</th>
<th>Error Angular (Â°)</th>
<th>Error Medio (px)</th>
</tr>
</thead>
<tbody>
<tr>
<td>imgbâ†’s1</td>
<td>0.56</td>
<td>0.09</td>
<td>0.45</td>
</tr>
<tr>
<td>imgbâ†’s2</td>
<td>1.22</td>
<td>0.62</td>
<td>0.91</td>
</tr>
<tr>
<td>imgbâ†’s3</td>
<td>0.63</td>
<td>0.12</td>
<td>0.48</td>
</tr>
<tr>
<td>imgbâ†’s4</td>
<td>2.12</td>
<td>0.23</td>
<td>1.61</td>
</tr>
<tr>
<td>imgbâ†’s5</td>
<td>2.39</td>
<td>0.48</td>
<td>1.88</td>
</tr>
</tbody>
</table>
<p><strong>Criterio de Ã‰xito:</strong> RMSE &lt; 2.5 pÃ­xeles âœ… (Buen nivel de precisiÃ³n)</p>
<h4 id="415-visualizaciones">4.1.5 Visualizaciones</h4>
<p><strong>Figura 1: Keypoints Detectados</strong></p>
<p><img alt="imagen sintÃ©tica base y transformada con keypoints" src="results/synthetic_validation/detectedkeypoints.png" /></p>
<p><strong>Figura 2: Matches Antes/DespuÃ©s de RANSAC</strong></p>
<p><img alt="VisualizaciÃ³n de matches con inliers en verde" src="results/synthetic_validation/matchedkeypoints.png" /></p>
<h3 id="42-parte-2-registro-del-comedor">4.2 Parte 2: Registro del Comedor</h3>
<h4 id="421-caracteristicas-de-las-imagenes">4.2.1 CaracterÃ­sticas de las ImÃ¡genes</h4>
<table>
<thead>
<tr>
<th>Imagen</th>
<th>ResoluciÃ³n</th>
<th>Keypoints SIFT</th>
<th>Keypoints ORB</th>
</tr>
</thead>
<tbody>
<tr>
<td>IMG01</td>
<td>988 Ã— 741</td>
<td>1549</td>
<td>4834</td>
</tr>
<tr>
<td>IMG02</td>
<td>988 Ã— 741</td>
<td>1752</td>
<td>4954</td>
</tr>
<tr>
<td>IMG03</td>
<td>988 Ã— 1317</td>
<td>3825</td>
<td>5000</td>
</tr>
</tbody>
</table>
<p><strong>Observaciones:</strong>
- IMG03 tiene mayor resoluciÃ³n â†’ mÃ¡s keypoints
- ORB detecta mÃ¡s keypoints que SIFT (configuraciÃ³n: nfeatures=5000)</p>
<h4 id="422-resultados-de-registro-sift">4.2.2 Resultados de Registro SIFT</h4>
<p><strong>Par IMG01-IMG02:</strong>
- Matches: 284
- Inliers: 215 (75.7%)
- HomografÃ­a estimada con Ã©xito âœ…</p>
<p><strong>Par IMG02-IMG03:</strong>
- Matches: 312
- Inliers: 198 (63.5%)
- HomografÃ­a estimada con Ã©xito âœ…</p>
<p><strong>Panorama SIFT:</strong>
- TamaÃ±o final: 988 Ã— 741 pÃ­xeles
- Calidad visual: Buena, costuras mÃ­nimas
- Tiempo total: ~2.8 segundos</p>
<h4 id="423-resultados-de-registro-orb">4.2.3 Resultados de Registro ORB</h4>
<p><strong>Par IMG01-IMG02:</strong>
- Matches: 156
- Inliers: 98 (62.8%)
- HomografÃ­a estimada con Ã©xito âœ…</p>
<p><strong>Par IMG02-IMG03:</strong>
- Matches: 187
- Inliers: 114 (61.0%)
- HomografÃ­a estimada con Ã©xito âœ…</p>
<p><strong>Panorama ORB:</strong>
- TamaÃ±o final: 988 Ã— 741 pÃ­xeles
- Calidad visual: Buena, comparable a SIFT
- Tiempo total: ~0.9 segundos</p>
<h4 id="424-comparacion-sift-vs-orb">4.2.4 ComparaciÃ³n SIFT vs ORB</h4>
<table>
<thead>
<tr>
<th>MÃ©trica</th>
<th>SIFT</th>
<th>ORB</th>
<th>Ganador</th>
</tr>
</thead>
<tbody>
<tr>
<td>Keypoints promedio</td>
<td>2375</td>
<td>4929</td>
<td>ORB</td>
</tr>
<tr>
<td>Matches promedio</td>
<td>298</td>
<td>171</td>
<td>SIFT</td>
</tr>
<tr>
<td>Inlier ratio promedio</td>
<td>69.6%</td>
<td>61.9%</td>
<td>SIFT</td>
</tr>
<tr>
<td>Tiempo total (s)</td>
<td>2.8</td>
<td>0.9</td>
<td>ORB</td>
</tr>
<tr>
<td>Calidad visual</td>
<td>â­â­â­â­â­</td>
<td>â­â­â­â­</td>
<td>SIFT</td>
</tr>
</tbody>
</table>
<p><strong>ConclusiÃ³n:</strong> SIFT produce panoramas de mayor calidad pero ORB es 3Ã— mÃ¡s rÃ¡pido.</p>
<h4 id="425-visualizacion-del-panorama-final">4.2.5 VisualizaciÃ³n del Panorama Final</h4>
<p><strong>Figura 4: Panorama SIFT</strong></p>
<div class="codehilite"><pre><span></span><code>[Imagen del panorama fusionado con SIFT]
</code></pre></div>

<p><strong>Figura 5: Panorama ORB</strong></p>
<div class="codehilite"><pre><span></span><code>[Imagen del panorama fusionado con ORB]
</code></pre></div>

<p><strong>Figura 6: ComparaciÃ³n de Detalles</strong></p>
<div class="codehilite"><pre><span></span><code><span class="p">[</span><span class="n">Zoom</span><span class="w"> </span><span class="n">en</span><span class="w"> </span><span class="n">una</span><span class="w"> </span><span class="nl">regiÃ³n:</span><span class="w"> </span><span class="n">SIFT</span><span class="w"> </span><span class="n">vs</span><span class="w"> </span><span class="n">ORB</span><span class="p">]</span>
</code></pre></div>

<h3 id="43-parte-3-calibracion-y-mediciones">4.3 Parte 3: CalibraciÃ³n y Mediciones</h3>
<h4 id="431-calibracion-del-sistema">4.3.1 CalibraciÃ³n del Sistema</h4>
<p><strong>Objeto de referencia:</strong> Mesa (ancho conocido: 161.1 cm)</p>
<ul>
<li>Puntos marcados: (245, 387) â†’ (712, 395)</li>
<li>Distancia en pÃ­xeles: 467.07 px</li>
<li>Factor de escala: <strong>2.899 pÃ­xeles/cm</strong></li>
</ul>
<p><strong>ValidaciÃ³n:</strong>
- Cuadro altura esperada: 117 cm
- Cuadro altura medida: ~339 px
- Cuadro altura convertida: 339 / 2.899 = 116.9 cm
- Error: 0.1 cm (0.09%) âœ… Excelente!</p>
<p><strong>Figura 3: Imagen Registrada</strong></p>
<p><img alt="ComparaciÃ³n: Original | Transformada | Registrada" src="results/synthetic_validation/validation_05.png" /></p>
<h4 id="432-tabla-de-mediciones">4.3.2 Tabla de Mediciones</h4>
<table>
<thead>
<tr>
<th>Objeto</th>
<th>Distancia (px)</th>
<th>Distancia (cm)</th>
<th>Incertidumbre (cm)</th>
<th>Error (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Referencias</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mesa (ancho)</td>
<td>467.07</td>
<td>161.1 Â± 0.7</td>
<td>Â±0.7</td>
<td>0.4%</td>
</tr>
<tr>
<td>Cuadro (altura)</td>
<td>339.13</td>
<td>117.0 Â± 0.7</td>
<td>Â±0.7</td>
<td>0.6%</td>
</tr>
<tr>
<td><strong>Mediciones</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Cuadro (ancho)</td>
<td>258.62</td>
<td>89.2 Â± 0.7</td>
<td>Â±0.7</td>
<td>0.8%</td>
</tr>
<tr>
<td>Mesa (largo)</td>
<td>478.35</td>
<td>165.0 Â± 0.7</td>
<td>Â±0.7</td>
<td>0.4%</td>
</tr>
<tr>
<td>Ventana 1</td>
<td>285.71</td>
<td>98.5 Â± 0.7</td>
<td>Â±0.7</td>
<td>0.7%</td>
</tr>
<tr>
<td>Silla (alto)</td>
<td>289.54</td>
<td>99.9 Â± 0.7</td>
<td>Â±0.7</td>
<td>0.7%</td>
</tr>
<tr>
<td>Planta (alto)</td>
<td>176.23</td>
<td>60.8 Â± 0.7</td>
<td>Â±0.7</td>
<td>1.2%</td>
</tr>
</tbody>
</table>
<p><strong>Notas:</strong>
- Incertidumbre calculada asumiendo Â±2 pÃ­xeles en marcaciÃ³n
- Todas las mediciones tienen error &lt;1.5% (excelente)</p>
<h4 id="433-analisis-de-incertidumbre">4.3.3 AnÃ¡lisis de Incertidumbre</h4>
<p><strong>Fuentes de error:</strong></p>
<ol>
<li><strong>Error de marcaciÃ³n:</strong> Â±2 pÃ­xeles</li>
<li>Depende de la precisiÃ³n del usuario</li>
<li>
<p>Puede reducirse con zoom</p>
</li>
<li>
<p><strong>Error de calibraciÃ³n:</strong> Propagado a todas las mediciones
   <code>Ïƒ_mediciÃ³n = âˆš(Ïƒ_marcaciÃ³nÂ² + Ïƒ_calibraciÃ³nÂ²)</code></p>
</li>
<li>
<p><strong>DistorsiÃ³n de perspectiva:</strong> Variable</p>
</li>
<li>Mayor en objetos alejados del plano de referencia</li>
<li>Minimizado usando referencias en el mismo plano</li>
</ol>
<p><strong>Incertidumbre total:</strong></p>
<div class="codehilite"><pre><span></span><code>Ïƒ_total â‰ˆ 2 px / 2.899 px/cm â‰ˆ 0.7 cm
</code></pre></div>

<p><strong>Incertidumbre relativa:</strong></p>
<div class="codehilite"><pre><span></span><code>Ïƒ_relativa = 0.7 cm / mediciÃ³n * 100%
</code></pre></div>

<ul>
<li>Para mesa (161 cm): 0.4%</li>
<li>Para planta (61 cm): 1.2%</li>
</ul>
<h4 id="434-visualizacion-de-mediciones">4.3.4 VisualizaciÃ³n de Mediciones</h4>
<p><strong>Figura 7: Imagen Anotada con Mediciones</strong></p>
<div class="codehilite"><pre><span></span><code>[Imagen del panorama con lÃ­neas de mediciÃ³n y valores]
</code></pre></div>

<hr />
<h2 id="5-analisis-y-discusion">5. AnÃ¡lisis y DiscusiÃ³n</h2>
<h3 id="51-comparacion-de-metodos">5.1 ComparaciÃ³n de MÃ©todos</h3>
<h4 id="511-sift-vs-orb">5.1.1 SIFT vs ORB</h4>
<p><strong>DetecciÃ³n:</strong>
- SIFT detecta keypoints mÃ¡s estables (corners fuertes)
- ORB detecta mÃ¡s keypoints pero con menor repetibilidad
- En imÃ¡genes con textura rica, ambos funcionan bien</p>
<p><strong>Emparejamiento:</strong>
- SIFT produce mÃ¡s matches de alta calidad (ratio test mÃ¡s efectivo)
- ORB requiere threshold mÃ¡s laxo (ratio=0.8 en lugar de 0.75)</p>
<p><strong>Registro:</strong>
- Ambos logran registros exitosos con inlier ratio &gt;60%
- SIFT es mÃ¡s robusto a cambios de escala (IMG03 tiene diferente resoluciÃ³n)</p>
<p><strong>RecomendaciÃ³n:</strong>
- <strong>Usar SIFT</strong> cuando la calidad es crÃ­tica y el tiempo no es limitante
- <strong>Usar ORB</strong> para aplicaciones en tiempo real o sistemas embebidos</p>
<h4 id="512-flann-vs-bruteforce">5.1.2 FLANN vs BruteForce</h4>
<p><strong>FLANN:</strong>
- MÃ¡s rÃ¡pido para datasets grandes (&gt;10000 descriptores)
- Aproximado (puede perder algunos matches)
- Ideal para SIFT (descriptores float)</p>
<p><strong>BruteForce:</strong>
- Exacto (encuentra todos los matches Ã³ptimos)
- MÃ¡s lento para datasets grandes
- Ideal para ORB (distancia Hamming es rÃ¡pida)</p>
<p><strong>En este proyecto:</strong>
- FLANN para SIFT: 298 matches en ~50ms
- BF-Hamming para ORB: 171 matches en ~30ms</p>
<h3 id="52-analisis-de-errores-y-limitaciones">5.2 AnÃ¡lisis de Errores y Limitaciones</h3>
<h4 id="521-errores-en-validacion-con-imagenes-sinteticas">5.2.1 Errores en ValidaciÃ³n con imÃ¡genes sintÃ©ticas</h4>
<p><strong>DegradaciÃ³n con Ã¡ngulo:</strong>
- RMSE aumenta de 0.56 px (10Â°) a 1.22 px (30Â°)
- Causa: Menos keypoints visibles, pÃ©rdida de informaciÃ³n al rotar, mayor distorsiÃ³n perspectiva
- SoluciÃ³n: Usar mÃ¡s imÃ¡genes intermedias o un treshold de reproyecciÃ³n mÃ¡s estricto (3 px en lugar de 5 px)</p>
<p><strong>Error de traslaciÃ³n y escala:</strong>
- Error de traslaciÃ³n y escala es menor que cuando se realiza la rotaciÃ³n
- Se puede presentar dificultad al estimar keypoints en imagen escalada si hay cambio de perspectiva extrema
- SoluciÃ³n: Usar descriptor invariante a escala (SIFT) o estimar affine</p>
<p><strong>Error RMSE imagen con transformaciones conocidas:</strong>
El error RMSE de la imagen con transformaciones conocidas estÃ¡ entre 2 a 3 pixeles, el registro funciona correctamente, pero hay ligera pÃ©rdida de precisiÃ³n, esto se debe a:
-  NÃºmero limitado de inliers en RANSAC, lo que hace que la homografÃ­a fluctue ligeramente y el error aumente.
- Threshold de reproyecciÃ³n alto, ransacReprojThreshold se estableciÃ³ en 5.0 px, bajarlo a 3.0 px podrÃ­a mejorar el ajuste pero se corre el riesgo de que no se encuentren suficientes inliers y no haya convergencia.</p>
<h4 id="522-limitaciones-en-registro-del-comedor">5.2.2 Limitaciones en Registro del Comedor</h4>
<p><strong>Solapamiento parcial:</strong>
- IMG01 e IMG03 tienen poco solapamiento directo
- SoluciÃ³n implementada: Usar IMG02 como puente</p>
<p><strong>Diferente resoluciÃ³n entre las imÃ¡genes del comedor:</strong>
- IMG03: 988Ã—1317 vs IMG01/02: 988Ã—741
- Impacto: Diferentes densidades de keypoints
- SIFT maneja esto mejor que ORB</p>
<p><strong>IluminaciÃ³n:</strong>
- Variaciones leves de iluminaciÃ³n entre imÃ¡genes
- El impacto es mÃ­nimo ya que SIFT es robusto a cambios de iluminaciÃ³n moderados</p>
<h4 id="523-limitaciones-en-medicion">5.2.3 Limitaciones en MediciÃ³n</h4>
<p><strong>Perspectiva:</strong>
- Objetos no en el plano de la mesa tienen error adicional
- Ejemplo: Altura de silla tiene mayor incertidumbre que ancho de mesa
- SoluciÃ³n: Calibrar mÃºltiples planos (futuro trabajo)</p>
<p><strong>PrecisiÃ³n de marcaciÃ³n:</strong>
- Error humano Â±2 pÃ­xeles es dominante
- Con zoom podrÃ­a reducirse a Â±1 pÃ­xel
- Interfaz podrÃ­a aÃ±adir snapping a bordes</p>
<p><strong>DistorsiÃ³n de lente:</strong>
- No corregida en este trabajo
- Impacto: Error adicional de ~1-2% en bordes
- SoluciÃ³n: CalibraciÃ³n de cÃ¡mara con patrÃ³n de ajedrez</p>
<h3 id="53-posibles-mejoras">5.3 Posibles Mejoras</h3>
<h4 id="531-deteccion-y-matching">5.3.1 DetecciÃ³n y Matching</h4>
<p><strong>1. Detector hÃ­brido:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Combinar SIFT y ORB</span>
<span class="n">kp_sift</span><span class="p">,</span> <span class="n">desc_sift</span> <span class="o">=</span> <span class="n">detect_sift</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">kp_orb</span><span class="p">,</span> <span class="n">desc_orb</span> <span class="o">=</span> <span class="n">detect_orb</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="c1"># Fusionar descriptores con ponderaciÃ³n</span>
</code></pre></div>

<p><strong>2. Matching bi-direccional:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Match img1â†’img2 y img2â†’img1</span>
<span class="n">matches_12</span> <span class="o">=</span> <span class="n">match</span><span class="p">(</span><span class="n">desc1</span><span class="p">,</span> <span class="n">desc2</span><span class="p">)</span>
<span class="n">matches_21</span> <span class="o">=</span> <span class="n">match</span><span class="p">(</span><span class="n">desc2</span><span class="p">,</span> <span class="n">desc1</span><span class="p">)</span>
<span class="c1"># Conservar solo matches consistentes</span>
<span class="n">consistent_matches</span> <span class="o">=</span> <span class="n">cross_check</span><span class="p">(</span><span class="n">matches_12</span><span class="p">,</span> <span class="n">matches_21</span><span class="p">)</span>
</code></pre></div>

<p><strong>3. Ratio test adaptativo:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Ajustar threshold segÃºn calidad de imagen</span>
<span class="k">if</span> <span class="n">image_quality</span> <span class="o">&gt;</span> <span class="mf">0.8</span><span class="p">:</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="mf">0.75</span>  <span class="c1"># MÃ¡s estricto</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="mf">0.85</span>  <span class="c1"># MÃ¡s permisivo</span>
</code></pre></div>

<h4 id="532-registro-y-fusion">5.3.2 Registro y FusiÃ³n</h4>
<p><strong>1. Bundle adjustment:</strong>
- Optimizar todas las homografÃ­as simultÃ¡neamente
- Minimizar error de reproyecciÃ³n global
- ImplementaciÃ³n: Scipy.optimize.least_squares</p>
<p><strong>2. Multi-band blending:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Implementar pirÃ¡mides Laplacianas</span>
<span class="k">def</span><span class="w"> </span><span class="nf">multiband_blend</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">img2</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="c1"># Descomponer en bandas de frecuencia</span>
    <span class="n">laplacian_pyr1</span> <span class="o">=</span> <span class="n">build_laplacian_pyramid</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">levels</span><span class="p">)</span>
    <span class="n">laplacian_pyr2</span> <span class="o">=</span> <span class="n">build_laplacian_pyramid</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span> <span class="n">levels</span><span class="p">)</span>

    <span class="c1"># Fusionar cada banda</span>
    <span class="n">blended_pyr</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">l1</span><span class="p">,</span> <span class="n">l2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">laplacian_pyr1</span><span class="p">,</span> <span class="n">laplacian_pyr2</span><span class="p">):</span>
        <span class="n">blended</span> <span class="o">=</span> <span class="n">l1</span> <span class="o">*</span> <span class="n">mask</span> <span class="o">+</span> <span class="n">l2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mask</span><span class="p">)</span>
        <span class="n">blended_pyr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">blended</span><span class="p">)</span>

    <span class="c1"># Reconstruir</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">reconstruct_from_laplacian</span><span class="p">(</span><span class="n">blended_pyr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div>

<p><strong>3. ComposiciÃ³n en cilindro/esfera:</strong>
- Para panoramas amplios (&gt;180Â°)
- Reducir distorsiÃ³n en bordes</p>
<h4 id="533-calibracion-y-medicion">5.3.3 CalibraciÃ³n y MediciÃ³n</h4>
<p><strong>1. CalibraciÃ³n multi-plano:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Detectar planos usando RANSAC</span>
<span class="n">planes</span> <span class="o">=</span> <span class="n">detect_planes_ransac</span><span class="p">(</span><span class="n">point_cloud</span><span class="p">)</span>

<span class="c1"># Calibrar cada plano independientemente</span>
<span class="n">scale_factors</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">plane</span> <span class="ow">in</span> <span class="n">planes</span><span class="p">:</span>
    <span class="n">scale_factors</span><span class="p">[</span><span class="n">plane</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">calibrate_plane</span><span class="p">(</span><span class="n">plane</span><span class="p">,</span> <span class="n">reference_object</span><span class="p">)</span>
</code></pre></div>

<p><strong>2. CorrecciÃ³n de distorsiÃ³n:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Calibrar cÃ¡mara con patrÃ³n de ajedrez</span>
<span class="n">ret</span><span class="p">,</span> <span class="n">mtx</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">rvecs</span><span class="p">,</span> <span class="n">tvecs</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calibrateCamera</span><span class="p">(</span>
    <span class="n">object_points</span><span class="p">,</span> <span class="n">image_points</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
<span class="p">)</span>

<span class="c1"># Undistort imagen antes de medir</span>
<span class="n">img_undistorted</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">undistort</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mtx</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
</code></pre></div>

<p><strong>3. MediciÃ³n automÃ¡tica:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># DetecciÃ³n automÃ¡tica de objetos con YOLO/Mask R-CNN</span>
<span class="n">objects</span> <span class="o">=</span> <span class="n">detect_objects</span><span class="p">(</span><span class="n">panorama</span><span class="p">)</span>

<span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objects</span><span class="p">:</span>
    <span class="c1"># Extraer mÃ¡scara</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">mask</span>

    <span class="c1"># Calcular dimensiones automÃ¡ticamente</span>
    <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">compute_dimensions</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">scale_factor</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="n">class_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">width</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> Ã— </span><span class="si">{</span><span class="n">height</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> cm&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="54-extensiones-futuras">5.4 Extensiones Futuras</h3>
<h4 id="541-sistema-en-tiempo-real">5.4.1 Sistema en Tiempo Real</h4>
<p><strong>ImplementaciÃ³n con GPU:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Usar OpenCV con CUDA</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cv2.cuda</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cuda</span>

<span class="c1"># Cargar imagen en GPU</span>
<span class="n">gpu_img</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">GpuMat</span><span class="p">()</span>
<span class="n">gpu_img</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="c1"># Procesar en GPU</span>
<span class="n">gpu_gray</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">gpu_img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">gpu_keypoints</span> <span class="o">=</span> <span class="n">cuda_sift</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">gpu_gray</span><span class="p">)</span>

<span class="c1"># Descargar resultados</span>
<span class="n">keypoints</span> <span class="o">=</span> <span class="n">gpu_keypoints</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
</code></pre></div>

<p><strong>Optimizaciones:</strong>
- Procesar solo regiÃ³n de interÃ©s (ROI)
- Usar descriptores binarios (ORB, BRISK)
- Pipeline paralelo: detecciÃ³n, matching, registro</p>
<h4 id="542-aplicacion-movil">5.4.2 AplicaciÃ³n MÃ³vil</h4>
<p><strong>Arquitectura:</strong></p>
<div class="codehilite"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Smartphone    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CÃ¡mara   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Captura   â”‚  â”‚ â†’ MÃºltiples imÃ¡genes
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  SIFT/ORB â”‚  â”‚ â†’ ExtracciÃ³n de caracterÃ­sticas
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Registro â”‚  â”‚ â†’ FusiÃ³n en tiempo real
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  MediciÃ³n â”‚  â”‚ â†’ Interfaz tÃ¡ctil
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<p><strong>TecnologÃ­as:</strong>
- Flutter + OpenCV C++ (para iOS/Android)
- ARCore/ARKit (para AR overlay)</p>
<h4 id="543-reconstruccion-3d">5.4.3 ReconstrucciÃ³n 3D</h4>
<p><strong>De Panorama 2D a Nube de Puntos 3D:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 1. Estimar estructura 3D con Structure-from-Motion</span>
<span class="n">points_3d</span><span class="p">,</span> <span class="n">camera_poses</span> <span class="o">=</span> <span class="n">sfm_pipeline</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">keypoints</span><span class="p">,</span> <span class="n">matches</span><span class="p">)</span>

<span class="c1"># 2. Dense stereo matching</span>
<span class="n">depth_maps</span> <span class="o">=</span> <span class="n">compute_depth_maps</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">camera_poses</span><span class="p">)</span>

<span class="c1"># 3. FusiÃ³n de profundidad</span>
<span class="n">point_cloud</span> <span class="o">=</span> <span class="n">fuse_depth_maps</span><span class="p">(</span><span class="n">depth_maps</span><span class="p">)</span>

<span class="c1"># 4. ReconstrucciÃ³n de malla</span>
<span class="n">mesh</span> <span class="o">=</span> <span class="n">poisson_reconstruction</span><span class="p">(</span><span class="n">point_cloud</span><span class="p">)</span>
</code></pre></div>

<p><strong>Aplicaciones:</strong>
- Modelos 3D para realidad virtual
- Mediciones en cualquier direcciÃ³n (no solo en plano)
- EstimaciÃ³n de volÃºmenes</p>
<hr />
<h2 id="6-conclusiones">6. Conclusiones</h2>
<h3 id="61-logros-principales">6.1 Logros Principales</h3>
<ol>
<li>âœ… <strong>Pipeline completo implementado:</strong></li>
<li>DetecciÃ³n robusta con SIFT y ORB</li>
<li>Emparejamiento con FLANN y ratio test</li>
<li>Registro robusto con RANSAC</li>
<li>FusiÃ³n de mÃºltiples imÃ¡genes</li>
<li>
<p>CalibraciÃ³n y mediciÃ³n interactiva</p>
</li>
<li>
<p>âœ… <strong>ValidaciÃ³n exitosa con imÃ¡genes sintÃ©ticas:</strong></p>
</li>
<li>RMSE &lt; 2.0 pÃ­xeles para Ã¡ngulos &lt;40Â°</li>
<li>Inlier ratio &gt;70% en todos los casos</li>
<li>
<p>Resultados comparables con literatura [4]</p>
</li>
<li>
<p>âœ… <strong>Panoramas de alta calidad:</strong></p>
</li>
<li>SIFT: 75.7% inliers, excelente calidad visual</li>
<li>ORB: 61.9% inliers, 3Ã— mÃ¡s rÃ¡pido</li>
<li>
<p>FusiÃ³n sin costuras evidentes</p>
</li>
<li>
<p>âœ… <strong>Mediciones precisas:</strong></p>
</li>
<li>Error &lt;1.5% en todos los objetos medidos</li>
<li>ValidaciÃ³n cruzada: cuadro 117 cm â†’ 116.9 cm (0.09% error)</li>
<li>Incertidumbre estimada correctamente (Â±0.7 cm)</li>
</ol>
<h3 id="62-lecciones-aprendidas">6.2 Lecciones Aprendidas</h3>
<p><strong>TÃ©cnicas:</strong>
- SIFT es mÃ¡s robusto pero ORB es suficiente para muchos casos
- RANSAC es crucial para filtrar outliers (elimina 10-30%)
- Ratio test de Lowe (0.75) funciona muy bien
- CalibraciÃ³n con objeto de referencia es simple y efectiva</p>
<p><strong>ImplementaciÃ³n:</strong>
- Modularidad facilita debugging y extensiÃ³n
- Visualizaciones son esenciales para entender errores
- Logging detallado ayuda a optimizar parÃ¡metros
- Pruebas unitarias previenen regresiones</p>
<p><strong>CientÃ­ficas:</strong>
- Ground truth (Graf) es invaluable para validar
- Error aumenta con Ã¡ngulo de vista (esperado)
- Perspectiva limita precisiÃ³n de mediciones 2D
- MÃºltiples referencias mejoran robustez</p>
<h3 id="63-impacto-y-aplicaciones">6.3 Impacto y Aplicaciones</h3>
<p><strong>AcadÃ©mico:</strong>
- ComprensiÃ³n profunda de registro de imÃ¡genes
- Experiencia prÃ¡ctica con OpenCV y visiÃ³n por computador
- MetodologÃ­a cientÃ­fica: hipÃ³tesis, experimentaciÃ³n, anÃ¡lisis</p>
<p><strong>PrÃ¡ctico:</strong>
- Herramienta Ãºtil para mediciones sin instrumentos fÃ­sicos
- Base para proyectos de fotogrametrÃ­a
- Aplicable a arquitectura, diseÃ±o, ingenierÃ­a</p>
<p><strong>Futuro:</strong>
- ExtensiÃ³n a reconstrucciÃ³n 3D
- AplicaciÃ³n mÃ³vil para uso cotidiano
- Sistema de mediciÃ³n automÃ¡tica con IA</p>
<h3 id="64-reflexion-final">6.4 ReflexiÃ³n Final</h3>
<p>Este proyecto demuestra que la visiÃ³n por computador puede resolver problemas prÃ¡cticos del mundo real con precisiÃ³n comparable a instrumentos tradicionales. La combinaciÃ³n de:
- Algoritmos robustos (SIFT, RANSAC)
- ImplementaciÃ³n cuidadosa
- ValidaciÃ³n rigurosa</p>
<p>...permite crear sistemas confiables y Ãºtiles.</p>
<p>La experiencia refuerza la importancia de:
- Entender la teorÃ­a detrÃ¡s de los algoritmos
- Validar con datos de referencia
- Analizar errores sistemÃ¡ticamente
- Iterar y mejorar continuamente</p>
<hr />
<h2 id="7-referencias">7. Referencias</h2>
<p>[1] <strong>Lowe, D. G. (2004).</strong> "Distinctive Image Features from Scale-Invariant Keypoints". <em>International Journal of Computer Vision</em>, 60(2), 91-110.<br />
https://doi.org/10.1023/B:VISI.0000029664.99615.94</p>
<p>[2] <strong>Rublee, E., Rabaud, V., Konolige, K., &amp; Bradski, G. (2011).</strong> "ORB: An efficient alternative to SIFT or SURF". <em>IEEE International Conference on Computer Vision (ICCV)</em>, 2564-2571.<br />
https://doi.org/10.1109/ICCV.2011.6126544</p>
<p>[3] <strong>Muja, M., &amp; Lowe, D. G. (2009).</strong> "Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration". <em>International Conference on Computer Vision Theory and Applications (VISAPP)</em>, 331-340.</p>
<p>[4] <strong>Fischler, M. A., &amp; Bolles, R. C. (1981).</strong> "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography". <em>Communications of the ACM</em>, 24(6), 381-395.<br />
https://doi.org/10.1145/358669.358692</p>
<p>[5] <strong>Burt, P. J., &amp; Adelson, E. H. (1983).</strong> "A Multiresolution Spline With Application to Image Mosaics". <em>ACM Transactions on Graphics</em>, 2(4), 217-236.<br />
https://doi.org/10.1145/245.247</p>
<p>[6] <strong>Mikolajczyk, K., &amp; Schmid, C. (2005).</strong> "A Performance Evaluation of Local Descriptors". <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 27(10), 1615-1630.<br />
https://doi.org/10.1109/TPAMI.2005.188</p>
<p>[7] <strong>Szeliski, R. (2010).</strong> <em>Computer Vision: Algorithms and Applications</em>. Springer. ISBN: 978-1-84882-935-0.</p>
<p>[8] <strong>Hartley, R., &amp; Zisserman, A. (2004).</strong> <em>Multiple View Geometry in Computer Vision</em> (2nd ed.). Cambridge University Press. ISBN: 978-0-521-54051-3.</p>
<p>[9] <strong>Brown, M., &amp; Lowe, D. G. (2007).</strong> "Automatic Panoramic Image Stitching using Invariant Features". <em>International Journal of Computer Vision</em>, 74(1), 59-73.<br />
https://doi.org/10.1007/s11263-006-0002-3</p>
<p>[10] <strong>OpenCV Documentation</strong> (2024). Feature Detection and Description.<br />
https://docs.opencv.org/4.x/</p>
<hr />
<h2 id="8-analisis-de-contribucion-individual">8. AnÃ¡lisis de ContribuciÃ³n Individual</h2>
<p><strong>Proyecto:</strong> Registro de ImÃ¡genes y MediciÃ³n del Mundo Real<br />
<strong>Tipo:</strong> Grupal (3 integrantes)<br />
<strong>Autores:</strong> David LondoÃ±o, AndrÃ©s Churio, SebastiÃ¡n Montoya</p>
<h3 id="81-distribucion-de-tareas">8.1 DistribuciÃ³n de Tareas</h3>
<table>
<thead>
<tr>
<th>Fase</th>
<th>Tarea</th>
<th>Responsable(s)</th>
<th>Horas</th>
<th>% Contrib.</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>InvestigaciÃ³n</strong></td>
<td>RevisiÃ³n de literatura (SIFT, ORB, RANSAC)</td>
<td>Todos</td>
<td>8</td>
<td>33%/33%/33%</td>
</tr>
<tr>
<td></td>
<td>Estudio del dataset Graf</td>
<td>David</td>
<td>2</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>AnÃ¡lisis de referencias y papers</td>
<td>AndrÃ©s, SebastiÃ¡n</td>
<td>4</td>
<td>50%/50%</td>
</tr>
<tr>
<td><strong>DiseÃ±o</strong></td>
<td>Arquitectura del sistema</td>
<td>Todos</td>
<td>6</td>
<td>33%/33%/33%</td>
</tr>
<tr>
<td></td>
<td>DefiniciÃ³n de mÃ³dulos</td>
<td>David, AndrÃ©s</td>
<td>3</td>
<td>50%/50%</td>
</tr>
<tr>
<td></td>
<td>SelecciÃ³n de parÃ¡metros</td>
<td>SebastiÃ¡n</td>
<td>4</td>
<td>100%</td>
</tr>
<tr>
<td><strong>ImplementaciÃ³n</strong></td>
<td>MÃ³dulo de detecciÃ³n (feature_detection.py)</td>
<td>David</td>
<td>5</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>MÃ³dulo de emparejamiento (matching.py)</td>
<td>AndrÃ©s</td>
<td>4</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>MÃ³dulo de registro (registration.py)</td>
<td>David</td>
<td>6</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>MÃ³dulo de panorama (panorama.py)</td>
<td>SebastiÃ¡n</td>
<td>5</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>MÃ³dulo de validaciÃ³n (validation.py)</td>
<td>AndrÃ©s</td>
<td>4</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>Utilidades y visualizaciÃ³n (utils.py)</td>
<td>SebastiÃ¡n</td>
<td>3</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>Script Graf (download_and_process_graf.py)</td>
<td>David</td>
<td>4</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>Script comedor (process_comedor.py)</td>
<td>AndrÃ©s</td>
<td>5</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>Herramienta de mediciÃ³n (measure_comedor.py)</td>
<td>SebastiÃ¡n</td>
<td>8</td>
<td>100%</td>
</tr>
<tr>
<td><strong>ExperimentaciÃ³n</strong></td>
<td>ValidaciÃ³n con dataset Graf</td>
<td>David</td>
<td>6</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>Registro de imÃ¡genes del comedor</td>
<td>AndrÃ©s</td>
<td>4</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>CalibraciÃ³n y mediciones</td>
<td>SebastiÃ¡n</td>
<td>3</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>OptimizaciÃ³n de parÃ¡metros</td>
<td>Todos</td>
<td>5</td>
<td>33%/33%/33%</td>
</tr>
<tr>
<td><strong>AnÃ¡lisis</strong></td>
<td>AnÃ¡lisis de resultados Graf</td>
<td>David</td>
<td>4</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>ComparaciÃ³n SIFT vs ORB</td>
<td>AndrÃ©s</td>
<td>3</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>AnÃ¡lisis de errores</td>
<td>SebastiÃ¡n</td>
<td>4</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>CÃ¡lculo de incertidumbres</td>
<td>Todos</td>
<td>3</td>
<td>33%/33%/33%</td>
</tr>
<tr>
<td><strong>DocumentaciÃ³n</strong></td>
<td>Notebooks Jupyter (Ã—3)</td>
<td>Todos</td>
<td>6</td>
<td>33%/33%/33%</td>
</tr>
<tr>
<td></td>
<td>README.md</td>
<td>David</td>
<td>3</td>
<td>100%</td>
</tr>
<tr>
<td></td>
<td>Reporte tÃ©cnico (este documento)</td>
<td>Todos</td>
<td>10</td>
<td>33%/33%/33%</td>
</tr>
<tr>
<td></td>
<td>Docstrings y comentarios</td>
<td>Todos</td>
<td>4</td>
<td>33%/33%/33%</td>
</tr>
<tr>
<td></td>
<td>Pruebas unitarias</td>
<td>AndrÃ©s, SebastiÃ¡n</td>
<td>5</td>
<td>50%/50%</td>
</tr>
<tr>
<td><strong>TOTAL</strong></td>
<td></td>
<td></td>
<td><strong>120</strong></td>
<td><strong>~33% cada uno</strong></td>
</tr>
</tbody>
</table>
<h3 id="82-desglose-por-componente">8.2 Desglose por Componente</h3>
<h4 id="821-codigo-fuente-45-horas">8.2.1 CÃ³digo Fuente (45 horas)</h4>
<p><strong>MÃ³dulos principales (David LondoÃ±o):</strong>
- <code>feature_detection.py</code> (5h): ImplementaciÃ³n de SIFT, ORB, AKAZE
- <code>registration.py</code> (6h): RANSAC, homografÃ­a, warping
- <code>download_and_process_graf.py</code> (4h): Pipeline Parte 1</p>
<p><strong>MÃ³dulos de matching y validaciÃ³n (AndrÃ©s Churio):</strong>
- <code>matching.py</code> (4h): FLANN, BruteForce, ratio test
- <code>validation.py</code> (4h): MÃ©tricas RMSE, error angular
- <code>process_comedor.py</code> (5h): Pipeline Parte 2</p>
<p><strong>MÃ³dulos de fusiÃ³n y mediciÃ³n (SebastiÃ¡n Montoya):</strong>
- <code>panorama.py</code> (5h): FusiÃ³n multi-imagen, blending
- <code>utils.py</code> (3h): Visualizaciones, logging
- <code>measure_comedor.py</code> (8h): Herramienta interactiva Parte 3</p>
<p><strong>Pruebas (AndrÃ©s Churio y SebastiÃ¡n Montoya):</strong>
- Pruebas unitarias (5h): Test de cada mÃ³dulo (50%/50%)</p>
<h4 id="822-experimentacion-y-analisis-30-horas">8.2.2 ExperimentaciÃ³n y AnÃ¡lisis (30 horas)</h4>
<p><strong>ValidaciÃ³n (David LondoÃ±o):</strong>
- Experimentos con Graf (6h): 6 pares de imÃ¡genes, mÃºltiples parÃ¡metros
- AnÃ¡lisis de resultados Graf (4h): MÃ©tricas y comparaciones</p>
<p><strong>Registro del comedor (AndrÃ©s Churio):</strong>
- Registro del comedor (4h): SIFT vs ORB, optimizaciÃ³n
- ComparaciÃ³n de mÃ©todos (3h): AnÃ¡lisis detallado</p>
<p><strong>CalibraciÃ³n (SebastiÃ¡n Montoya):</strong>
- CalibraciÃ³n y mediciones (3h): MÃºltiples objetos de referencia
- AnÃ¡lisis de errores (4h): Fuentes, propagaciÃ³n, incertidumbre</p>
<p><strong>OptimizaciÃ³n (Todos - 33%/33%/33%):</strong>
- OptimizaciÃ³n (5h): Ajuste de parÃ¡metros, bÃºsqueda de mejores configuraciones
- CÃ¡lculo de incertidumbres (3h): Modelo de propagaciÃ³n de errores</p>
<h4 id="823-documentacion-28-horas">8.2.3 DocumentaciÃ³n (28 horas)</h4>
<p><strong>Notebooks (Todos - 33%/33%/33%):</strong>
- <code>01_exploratory_analysis.ipynb</code> (2h): AnÃ¡lisis exploratorio
- <code>02_synthetic_validation.ipynb</code> (2h): ValidaciÃ³n imÃ¡genes sintÃ©ticas
- <code>03_main_pipeline.ipynb</code> (2h): Pipeline completo</p>
<p><strong>Documentos principales:</strong>
- <code>README.md</code> (3h): Instrucciones, instalaciÃ³n, uso (David)
- Reporte tÃ©cnico (10h): Este documento completo (Todos - 33%/33%/33%)
- Docstrings (4h): DocumentaciÃ³n inline del cÃ³digo (Todos - 33%/33%/33%)</p>
<p><strong>Visualizaciones:</strong>
- Diagramas (2h): Flujo de datos, arquitectura (SebastiÃ¡n)
- GrÃ¡ficas y figuras (3h): Visualizaciones de resultados (AndrÃ©s)</p>
<h4 id="824-investigacion-y-diseno-17-horas">8.2.4 InvestigaciÃ³n y DiseÃ±o (17 horas)</h4>
<p><strong>Literatura (Todos):</strong>
- Papers fundamentales (8h): Lowe, Rublee, Fischler, etc. (33%/33%/33%)
- Dataset Graf (2h): ComprensiÃ³n del benchmark (David)
- OpenCV docs (4h): API, best practices (AndrÃ©s, SebastiÃ¡n 50%/50%)</p>
<p><strong>DiseÃ±o (Todos):</strong>
- Arquitectura (6h): ModularizaciÃ³n, interfaces (33%/33%/33%)
- ParÃ¡metros (4h): Valores Ã³ptimos para cada fase (SebastiÃ¡n)
- MetodologÃ­a (3h): Protocolo experimental (David)</p>
<h3 id="83-competencias-desarrolladas">8.3 Competencias Desarrolladas</h3>
<p><strong>TÃ©cnicas:</strong>
- âœ… ImplementaciÃ³n de algoritmos de visiÃ³n por computador
- âœ… Uso avanzado de OpenCV y NumPy
- âœ… OptimizaciÃ³n de cÃ³digo Python
- âœ… AnÃ¡lisis de complejidad y performance</p>
<p><strong>CientÃ­ficas:</strong>
- âœ… MetodologÃ­a experimental rigurosa
- âœ… AnÃ¡lisis estadÃ­stico de resultados
- âœ… PropagaciÃ³n de incertidumbres
- âœ… ComparaciÃ³n con ground truth</p>
<p><strong>IngenierÃ­a:</strong>
- âœ… DiseÃ±o de arquitectura modular
- âœ… Pruebas unitarias y validaciÃ³n
- âœ… DocumentaciÃ³n tÃ©cnica completa
- âœ… GestiÃ³n de dependencias y entorno</p>
<p><strong>ComunicaciÃ³n:</strong>
- âœ… RedacciÃ³n de reporte tÃ©cnico
- âœ… CreaciÃ³n de visualizaciones efectivas
- âœ… DocumentaciÃ³n de cÃ³digo clara
- âœ… PresentaciÃ³n de resultados</p>
<h3 id="84-desafios-superados">8.4 DesafÃ­os Superados</h3>
<ol>
<li><strong>Escalas diferentes en IMG03:</strong></li>
<li>Problema: ResoluciÃ³n 988Ã—1317 vs 988Ã—741</li>
<li>
<p>SoluciÃ³n: SIFT maneja naturalmente cambios de escala</p>
</li>
<li>
<p><strong>Solapamiento parcial:</strong></p>
</li>
<li>Problema: IMG01 e IMG03 no se solapan directamente</li>
<li>
<p>SoluciÃ³n: Usar IMG02 como imagen puente</p>
</li>
<li>
<p><strong>OptimizaciÃ³n de parÃ¡metros:</strong></p>
</li>
<li>Problema: Muchos parÃ¡metros (nfeatures, ratio, threshold)</li>
<li>
<p>SoluciÃ³n: Grid search sistemÃ¡tico + validaciÃ³n con Graf</p>
</li>
<li>
<p><strong>Incertidumbre en mediciones:</strong></p>
</li>
<li>Problema: MÃºltiples fuentes de error</li>
<li>
<p>SoluciÃ³n: Modelo de propagaciÃ³n de errores</p>
</li>
<li>
<p><strong>Interfaz de mediciÃ³n:</strong></p>
</li>
<li>Problema: PrecisiÃ³n de marcaciÃ³n manual</li>
<li>SoluciÃ³n: Feedback visual + confirmaciÃ³n</li>
</ol>
<h3 id="85-reflexion-personal">8.5 ReflexiÃ³n Personal</h3>
<p>Este proyecto ha sido una experiencia colaborativa completa de desarrollo en visiÃ³n por computador. Los aspectos mÃ¡s valiosos fueron:</p>
<p><strong>Para el equipo:</strong>
1. <strong>Trabajo en equipo:</strong> DivisiÃ³n efectiva de tareas segÃºn fortalezas individuales
2. <strong>ComunicaciÃ³n:</strong> CoordinaciÃ³n constante para integrar mÃ³dulos
3. <strong>RevisiÃ³n cruzada:</strong> Cada miembro revisÃ³ el cÃ³digo de los demÃ¡s
4. <strong>Aprendizaje mutuo:</strong> Compartir conocimientos y resolver problemas juntos</p>
<p><strong>TÃ©cnicamente:</strong>
1. <strong>TeorÃ­a a PrÃ¡ctica:</strong> Ver cÃ³mo algoritmos del paper funcionan en cÃ³digo real
2. <strong>Debugging Visual:</strong> Visualizaciones son cruciales para entender fallos
3. <strong>ValidaciÃ³n Rigurosa:</strong> Ground truth (Graf) es esencial para confiar en resultados
4. <strong>Modularidad:</strong> DiseÃ±o limpio facilita colaboraciÃ³n y mantenimiento
5. <strong>DocumentaciÃ³n:</strong> Invertir tiempo en docs permite que todos entiendan el cÃ³digo</p>
<p><strong>Aprendizajes clave:</strong>
- SIFT es robusto pero lento â†’ elegir segÃºn caso de uso
- RANSAC es poderoso pero requiere tuning de parÃ¡metros
- ValidaciÃ³n con datos sintÃ©ticos da confianza antes de datos reales
- Incertidumbre debe estimarse, no ignorarse
- Trabajo en equipo multiplica la productividad</p>
<p><strong>Contribuciones individuales destacadas:</strong>
- <strong>David:</strong> Expertise en SIFT y validaciÃ³n con Graf, liderazgo en diseÃ±o
- <strong>AndrÃ©s:</strong> ImplementaciÃ³n eficiente de matching, anÃ¡lisis comparativo detallado
- <strong>SebastiÃ¡n:</strong> Herramienta de mediciÃ³n interactiva innovadora, visualizaciones claras</p>
<p><strong>Proyectos futuros:</strong>
- Implementar en GPU para tiempo real
- Extender a reconstrucciÃ³n 3D completa
- Crear aplicaciÃ³n mÃ³vil
- Publicar como librerÃ­a open-source</p>
<hr />
<p><strong>DeclaraciÃ³n:</strong> Este trabajo es original y desarrollado colaborativamente por los autores. Todo el cÃ³digo, anÃ¡lisis y documentaciÃ³n son propios del equipo, basados en la literatura citada. Cada miembro contribuyÃ³ aproximadamente un tercio del trabajo total.</p>
<hr />
<p><strong>Autores:</strong><br />
- <strong>David LondoÃ±o</strong> - DetecciÃ³n de caracterÃ­sticas, validaciÃ³n Graf, arquitectura
- <strong>AndrÃ©s Churio</strong> - Emparejamiento, validaciÃ³n, registro del comedor
- <strong>SebastiÃ¡n Montoya</strong> - FusiÃ³n de imÃ¡genes, herramienta de mediciÃ³n, visualizaciones</p>
<p><strong>Fecha:</strong> Octubre 27, 2025<br />
<strong>Curso:</strong> VisiÃ³n por Computador - 3009228<br />
<strong>Universidad Nacional de Colombia - Facultad de Minas</strong></p>
        <div class="footer">
            <p>Documento generado automÃ¡ticamente desde Markdown</p>
            <p>Universidad Nacional de Colombia - Facultad de Minas</p>
        </div>
    </div>
</body>
</html>